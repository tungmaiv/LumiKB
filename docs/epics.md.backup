# LumiKB - Epic Breakdown

**Author:** Tung Vu
**Date:** 2025-11-23
**Project Level:** Enterprise SaaS B2B Platform
**Target Scale:** MVP 1 - Internal Pilot (20+ users, 5000 documents)

---

## Overview

This document provides the complete epic and story breakdown for LumiKB, decomposing the requirements from the [PRD](./prd.md) into implementable stories.

**Living Document Notice:** This is the initial version. Stories will be updated after implementation begins to incorporate technical discoveries and refinements.

**Design Principles Applied:**
- **Citation-first**: Every search/generate story includes citation acceptance criteria
- **User value per epic**: Each epic delivers demo-able capability
- **Risk front-loading**: Auth, audit, consistency patterns early
- **Journey alignment**: Epics map to user journeys (Sarah's RFP flow, David's contribution flow)
- **KISS**: 5 focused epics, combining related capabilities
- **Single-session stories**: Each story completable in one dev agent session

**Epic Summary:**

| Epic | Name | User Value | Story Count |
|------|------|------------|-------------|
| 1 | Foundation & Authentication | Login, explore sample KB with demo docs | 10 |
| 2 | Knowledge Base & Document Management | Create KBs, upload and process documents | 12 |
| 3 | Semantic Search & Citations | Search and get answers WITH citations | 11 |
| 4 | Chat & Document Generation | Chat, generate drafts with citations, export | 10 |
| 5 | Administration & Polish | Full admin dashboard, onboarding wizard | 11 (includes 2 technical debt) |

**Total Stories:** 54 (52 features + 2 technical debt)

---

## Functional Requirements Inventory

### User Account & Access (FR1-FR8)
- **FR1**: Users can create accounts with email and password
- **FR2**: Users can log in securely and maintain sessions
- **FR3**: Users can reset passwords via email verification
- **FR4**: Users can update their profile information
- **FR5**: Administrators can create, modify, and deactivate user accounts
- **FR6**: Administrators can assign users to Knowledge Bases with specific permissions
- **FR7**: Users can only access Knowledge Bases they have been granted permission to
- **FR8**: System enforces session timeout and secure logout
- **FR8a**: First-time users see an onboarding tutorial emphasizing citation verification
- **FR8b**: First-time users see a Getting Started wizard
- **FR8c**: System provides a sample Knowledge Base with demo documents

### Knowledge Base Management (FR9-FR14)
- **FR9**: Administrators can create new Knowledge Bases with name and description
- **FR10**: Administrators can configure KB-level settings (retention policy, access defaults)
- **FR10a**: Administrators can configure document processing settings per KB
- **FR11**: Administrators can archive or delete Knowledge Bases
- **FR12**: Users can view list of Knowledge Bases they have access to
- **FR12a**: Users can view KB summary information (document count, total size, last updated)
- **FR12b**: Administrators can view detailed KB statistics
- **FR12c**: System suggests relevant Knowledge Bases based on pasted content (Smart KB Suggestions)
- **FR12d**: Users can view recently accessed Knowledge Bases
- **FR13**: Users can switch between Knowledge Bases within a session
- **FR14**: Each Knowledge Base maintains isolated storage and vector indices

### Document Ingestion (FR15-FR23)
- **FR15**: Users with write permission can upload documents to a Knowledge Base
- **FR16**: System accepts PDF, DOCX, and Markdown file formats
- **FR17**: System processes uploaded documents: extraction, chunking, embedding
- **FR18**: Users can see upload progress and processing status
- **FR19**: System notifies users when document processing completes
- **FR20**: Users can view list of documents in a Knowledge Base
- **FR21**: Users can view document metadata (name, upload date, size, uploader)
- **FR22**: Users with write permission can delete documents from a Knowledge Base
- **FR23**: System removes deleted documents from storage and vector index completely
- **FR23a**: Users with write permission can re-upload/update existing documents
- **FR23b**: System supports incremental vector updates when documents are modified
- **FR23c**: System maintains document version awareness

### Semantic Search & Q&A (FR24-FR30)
- **FR24**: Users can ask natural language questions against a Knowledge Base
- **FR24a**: Users can perform Quick Search for simple lookups
- **FR24b**: Quick Search is accessible via always-visible search bar
- **FR24c**: Quick Search is accessible via keyboard shortcut (Cmd/Ctrl+K)
- **FR24d**: Users can set preference for default search mode
- **FR25**: System performs semantic search to find relevant document chunks
- **FR26**: System returns answers synthesized from retrieved content
- **FR27**: Every answer includes citations linking to source documents
- **FR27a**: Citations are displayed INLINE with answers (always visible)
- **FR28**: Users can click citations to view source document context
- **FR28a**: Users can access and view the original source document
- **FR28b**: System highlights the relevant paragraph/section in source
- **FR29**: Users can search across multiple Knowledge Bases simultaneously
- **FR29a**: Cross-KB search is the DEFAULT behavior
- **FR30**: System displays confidence/relevance indicators for search results
- **FR30a**: System explains WHY each result is relevant
- **FR30b**: Users can perform quick actions on search results
- **FR30c**: Confidence indicators are ALWAYS shown for AI-generated content
- **FR30d**: Users can click "Verify All" to see all citations at once
- **FR30e**: Users can filter results to "Search within current KB"
- **FR30f**: System displays citation accuracy score

### Chat Interface (FR31-FR35)
- **FR31**: Users can engage in multi-turn conversations with the system
- **FR32**: System maintains conversation context within a session
- **FR33**: Users can start new conversation threads
- **FR34**: Users can view conversation history within current session
- **FR35**: System clearly distinguishes AI-generated content from quoted sources
- **FR35a**: System streams AI responses in real-time (word-by-word)
- **FR35b**: Users can see typing/thinking indicators

### Document Generation Assist (FR36-FR42)
- **FR36**: Users can request AI assistance to generate document drafts
- **FR37**: System supports generation of: RFP/RFI responses, questionnaires, checklists, gap analysis
- **FR38**: Generated content includes citations to source documents used
- **FR39**: Users can edit generated content before exporting
- **FR40**: Users can export generated documents in common formats (DOCX, PDF, MD)
- **FR40a**: Exported documents preserve citations and formatting accurately
- **FR40b**: System prompts "Have you verified the sources?" before export
- **FR41**: System allows users to provide context/instructions for generation
- **FR42**: Users can regenerate content with modified instructions
- **FR42a**: System displays generation progress and streams draft content
- **FR42b**: Upon completion, system shows summary of sources used
- **FR42c**: Users can provide feedback on generation quality
- **FR42d**: System offers alternative approaches when generation fails
- **FR42e**: System highlights low-confidence sections

### Citation & Provenance (FR43-FR46)
- **FR43**: Every AI-generated statement traces back to source document(s)
- **FR44**: Citations include document name, section, and page/location reference
- **FR45**: Users can preview cited source content without leaving current view
- **FR46**: System logs all sources used in each generation request

### Administration & Configuration (FR47-FR52)
- **FR47**: Administrators can view system-wide usage statistics
- **FR48**: Administrators can view audit logs with filters (user, action, date range)
- **FR49**: Administrators can export audit logs for compliance reporting
- **FR50**: Administrators can configure LLM provider settings
- **FR51**: Administrators can configure system-wide defaults
- **FR52**: Administrators can view and manage processing queue status

### Audit & Compliance (FR53-FR58)
- **FR53**: System logs every document upload with user, timestamp, and metadata
- **FR54**: System logs every search query with user, timestamp, and results summary
- **FR55**: System logs every generation request with user, timestamp, prompt, and sources
- **FR56**: System logs every user management action
- **FR57**: Audit logs are immutable and tamper-evident
- **FR58**: System supports configurable data retention policies per Knowledge Base

---

## FR Coverage Map

| Epic | FRs Covered | Coverage Summary |
|------|-------------|------------------|
| **Epic 1: Foundation & Authentication** | FR1-8, FR53 (infra), FR56-57 (infra) | Auth, sessions, audit infrastructure, demo KB |
| **Epic 2: KB & Document Management** | FR9-14, FR15-23, FR23a-c, FR53 | KB CRUD, document upload/processing pipeline |
| **Epic 3: Semantic Search & Citations** | FR24-30, FR24a-d, FR27a, FR28a-b, FR29a, FR30a-f, FR43-46, FR54 | Search, retrieval, citation system |
| **Epic 4: Chat & Document Generation** | FR31-35, FR35a-b, FR36-42, FR42a-e, FR55 | Chat interface, generation, export |
| **Epic 5: Administration & Polish** | FR47-52, FR58, FR8a-c, FR12b, FR12c-d | Admin dashboard, onboarding, audit UI |

---

## Epic 1: Foundation & Authentication

**Goal:** Establish project infrastructure, authentication system, and basic UI shell so users can login and explore the application with a demo Knowledge Base.

**User Value:** "I can login securely and immediately explore sample knowledge to understand what LumiKB does."

**FRs Covered:** FR1-8, FR53 (infrastructure), FR56-57 (infrastructure)

**Technical Foundation:**
- Next.js 15 + shadcn/ui frontend
- FastAPI + FastAPI-Users backend
- PostgreSQL database with audit schema
- Redis for sessions and cache
- Docker Compose for local development

---

### Story 1.1: Project Initialization and Repository Setup

As a **developer**,
I want **the project repository initialized with proper structure**,
So that **I have a consistent foundation for all subsequent development**.

**Acceptance Criteria:**

**Given** a new development environment
**When** I clone the repository and run setup commands
**Then** both frontend and backend start successfully

**And** the project structure matches the architecture specification:
- `frontend/` - Next.js 15 with App Router
- `backend/` - FastAPI with proper module structure
- `infrastructure/` - Docker Compose files
- `docs/` - Project documentation

**And** all required tools are configured:
- TypeScript strict mode enabled
- ESLint + Prettier configured
- Python linting (ruff) configured
- Git hooks for pre-commit checks

**Prerequisites:** None (first story)

**Technical Notes:**
- Use `npx create-next-app@latest` with flags from architecture doc
- Use `npx shadcn@latest init` for component library
- Python 3.11 required (redis-py compatibility)
- Reference: [architecture.md](./architecture.md) Project Initialization section

---

### Story 1.2: Database Schema and Migration Setup

As a **developer**,
I want **the PostgreSQL database schema established with migrations**,
So that **data models are versioned and reproducible**.

**Acceptance Criteria:**

**Given** PostgreSQL is running via Docker Compose
**When** I run `alembic upgrade head`
**Then** all tables are created successfully

**And** the following tables exist:
- `users` (id, email, hashed_password, is_active, is_superuser, created_at, updated_at)
- `knowledge_bases` (id, name, description, owner_id, status, created_at, updated_at)
- `kb_permissions` (id, user_id, kb_id, permission_level, created_at)
- `documents` (id, kb_id, name, file_path, status, chunk_count, created_at, updated_at)
- `outbox` (id, event_type, aggregate_id, payload, created_at, processed_at, attempts, last_error)
- `audit.events` (id, timestamp, user_id, action, resource_type, resource_id, details, ip_address)

**And** audit schema has INSERT-only permissions for application role

**Prerequisites:** Story 1.1

**Technical Notes:**
- Use SQLAlchemy 2.0 async models
- Document status enum: PENDING, PROCESSING, READY, FAILED, ARCHIVED
- KB permission levels: READ, WRITE, ADMIN
- Reference: [architecture.md](./architecture.md) Data Architecture section

---

### Story 1.3: Docker Compose Development Environment

As a **developer**,
I want **a complete local development environment via Docker Compose**,
So that **all services can be started with a single command**.

**Acceptance Criteria:**

**Given** Docker and Docker Compose are installed
**When** I run `docker compose up -d`
**Then** all required services start successfully:
- PostgreSQL (port 5432)
- Redis (port 6379)
- MinIO (ports 9000, 9001)
- Qdrant (ports 6333, 6334)
- LiteLLM Proxy (port 4000)

**And** health checks pass for all services
**And** services persist data in named volumes
**And** `.env.example` documents all required environment variables

**Prerequisites:** Story 1.1

**Technical Notes:**
- Use official images with pinned versions
- Configure health checks for each service
- Network isolation between services
- Reference: [architecture.md](./architecture.md) Deployment Architecture section

---

### Story 1.4: User Registration and Authentication Backend

As a **user**,
I want **to create an account and log in securely**,
So that **I can access the LumiKB application**.

**Acceptance Criteria:**

**Given** I am on the registration endpoint
**When** I submit valid email and password
**Then** my account is created with hashed password (argon2)
**And** I receive a success response

**Given** I have an account
**When** I submit correct credentials to login endpoint
**Then** I receive a JWT token in an httpOnly cookie
**And** the session is stored in Redis

**Given** I am logged in
**When** I access a protected endpoint
**Then** my JWT is validated and request proceeds

**Given** I am logged in
**When** I call the logout endpoint
**Then** my session is invalidated in Redis
**And** the JWT cookie is cleared

**And** all authentication events are logged to audit.events (FR56)
**And** failed login attempts are rate-limited

**Prerequisites:** Story 1.2, Story 1.3

**Technical Notes:**
- Use FastAPI-Users with SQLAlchemy backend
- JWT expiry: 60 minutes (configurable)
- Password requirements: minimum 8 characters
- Reference: [architecture.md](./architecture.md) Security Architecture section

---

### Story 1.5: User Profile and Password Management Backend

As a **user**,
I want **to update my profile and reset my password**,
So that **I can manage my account information**.

**Acceptance Criteria:**

**Given** I am logged in
**When** I call GET /api/v1/users/me
**Then** I receive my profile information (email, name, created_at)

**Given** I am logged in
**When** I call PATCH /api/v1/users/me with valid data
**Then** my profile is updated
**And** the change is logged to audit.events

**Given** I forgot my password
**When** I submit my email to password reset endpoint
**Then** a reset token is generated (expires in 1 hour)
**And** (mock) email would be sent with reset link

**Given** I have a valid reset token
**When** I submit a new password
**Then** my password is updated
**And** all existing sessions are invalidated
**And** the change is logged to audit.events

**Prerequisites:** Story 1.4

**Technical Notes:**
- Use FastAPI-Users built-in password reset flow
- Email sending is mocked for MVP (log to console)
- Reference: FR3, FR4

---

### Story 1.6: Admin User Management Backend

As an **administrator**,
I want **to manage user accounts**,
So that **I can control who has access to the system**.

**Acceptance Criteria:**

**Given** I am logged in as an admin
**When** I call GET /api/v1/admin/users
**Then** I receive a paginated list of all users

**Given** I am logged in as an admin
**When** I call POST /api/v1/admin/users with valid data
**Then** a new user account is created
**And** the action is logged to audit.events

**Given** I am logged in as an admin
**When** I call PATCH /api/v1/admin/users/{id} to deactivate
**Then** the user's is_active flag is set to false
**And** the user cannot log in
**And** the action is logged to audit.events

**Given** I am NOT an admin
**When** I try to access admin endpoints
**Then** I receive 403 Forbidden

**Prerequisites:** Story 1.4

**Technical Notes:**
- Admin check via is_superuser flag
- Pagination: default 20 per page
- Reference: FR5, FR56

---

### Story 1.7: Audit Logging Infrastructure

As a **compliance officer**,
I want **all significant actions logged immutably**,
So that **we can demonstrate compliance and investigate issues**.

**Acceptance Criteria:**

**Given** any auditable action occurs (login, logout, user change, etc.)
**When** the action completes
**Then** an audit event is written to audit.events table

**And** each audit event contains:
- timestamp (UTC)
- user_id (if authenticated)
- action (e.g., "user.login", "user.created")
- resource_type and resource_id (if applicable)
- details (JSON with context)
- ip_address

**And** the audit_writer role can only INSERT (no UPDATE, DELETE)
**And** audit events are written via a dedicated AuditService

**Given** high request volume
**When** audit logging occurs
**Then** it does not significantly impact request latency (async write)

**Prerequisites:** Story 1.2

**Technical Notes:**
- Use structlog for structured logging
- Audit writes should be async (background task)
- Reference: FR53, FR56, FR57
- Reference: [architecture.md](./architecture.md) Audit Schema section

---

### Story 1.8: Frontend Authentication UI

As a **user**,
I want **a clean login and registration interface**,
So that **I can access LumiKB easily**.

**Acceptance Criteria:**

**Given** I navigate to /login
**When** the page loads
**Then** I see a login form with email and password fields
**And** the design follows the Trust Blue color theme

**Given** I enter valid credentials and submit
**When** authentication succeeds
**Then** I am redirected to the dashboard
**And** my session is established

**Given** I enter invalid credentials
**When** authentication fails
**Then** I see a clear error message
**And** the form is not cleared

**Given** I click "Create Account"
**When** the registration form loads
**Then** I can enter email and password
**And** validation shows password requirements

**Given** I am logged in
**When** I click logout
**Then** I am logged out and redirected to login page

**Prerequisites:** Story 1.4, Story 1.1

**Technical Notes:**
- Use shadcn/ui form components
- Client-side validation with react-hook-form
- Store auth state in Zustand
- Reference: [ux-design-specification.md](./ux-design-specification.md) Visual Foundation section

---

### Story 1.9: Three-Panel Dashboard Shell

As a **user**,
I want **to see the main application layout after login**,
So that **I understand how to navigate LumiKB**.

**Acceptance Criteria:**

**Given** I am logged in
**When** I navigate to the dashboard
**Then** I see a three-panel layout:
- Left sidebar (260px): KB navigation area (placeholder)
- Center panel (flexible): Main content area with welcome message
- Right panel (320px): Citations panel (placeholder, collapsible)

**And** the header contains:
- LumiKB logo
- Search bar placeholder (disabled until Epic 3)
- User menu with profile and logout options

**And** the layout is responsive:
- Desktop (1280px+): Full three-panel
- Laptop (1024-1279px): Citations become tab
- Tablet (768-1023px): Sidebar in drawer
- Mobile (<768px): Single column with bottom nav

**And** dark mode toggle is available in user menu

**Prerequisites:** Story 1.8

**Technical Notes:**
- Use Tailwind CSS for responsive breakpoints
- Collapsible panels using Radix UI Collapsible
- Reference: [ux-design-specification.md](./ux-design-specification.md) Section 4 - Design Direction

---

### Story 1.10: Demo Knowledge Base Seeding

As a **first-time user**,
I want **to explore a sample Knowledge Base immediately**,
So that **I can understand LumiKB's value before uploading my own documents**.

**Acceptance Criteria:**

**Given** the system is freshly deployed
**When** the seed script runs
**Then** a "Sample Knowledge Base" is created
**And** it contains 3-5 demo documents (markdown files about LumiKB features)
**And** documents are processed and indexed in Qdrant

**Given** a new user logs in for the first time
**When** they view the KB list
**Then** they see "Sample Knowledge Base" with READ permission
**And** they can explore it immediately

**Given** the demo KB exists
**When** a user searches within it (after Epic 3)
**Then** they get meaningful results demonstrating the citation system

**Prerequisites:** Story 1.2, Story 1.3

**Technical Notes:**
- Seed script in `infrastructure/scripts/seed-data.sh`
- Demo docs stored in `infrastructure/seed/demo-docs/`
- Creates demo user if none exists (demo@lumikb.local / demo123)
- **Seeding Mechanism:** Uses direct Qdrant API to insert pre-computed embeddings (not the full processing pipeline from Epic 2). This allows demo data to exist before document processing is implemented.
- Pre-computed embeddings stored in `infrastructure/seed/demo-embeddings.json`
- This story sets up data; search functionality comes in Epic 3

---

## Epic 2: Knowledge Base & Document Management

**Goal:** Enable users to create Knowledge Bases and upload documents that are processed, chunked, and indexed for semantic search.

**User Value:** "I can create my own Knowledge Base, upload my documents, and see them processed and ready for search."

**FRs Covered:** FR9-14, FR15-23, FR23a-c, FR53

**Technical Foundation:**
- MinIO for document storage
- Celery workers for async processing
- unstructured for document parsing
- LangChain for chunking
- Qdrant for vector storage
- Outbox pattern for consistency

---

### Story 2.1: Knowledge Base CRUD Backend

As an **administrator**,
I want **to create and manage Knowledge Bases**,
So that **I can organize documents into logical collections**.

**Acceptance Criteria:**

**Given** I am logged in as an admin
**When** I call POST /api/v1/knowledge-bases with name and description
**Then** a new Knowledge Base is created
**And** a corresponding Qdrant collection is created (kb_{id})
**And** I am assigned ADMIN permission on the KB
**And** the action is logged to audit.events

**Given** a KB exists
**When** I call GET /api/v1/knowledge-bases/{id}
**Then** I receive KB details including document count and status

**Given** I have ADMIN permission on a KB
**When** I call PATCH /api/v1/knowledge-bases/{id}
**Then** the KB name/description is updated

**Given** I have ADMIN permission on a KB
**When** I call DELETE /api/v1/knowledge-bases/{id}
**Then** the KB status is set to ARCHIVED
**And** it no longer appears in normal listings
**And** the Qdrant collection is deleted

**Prerequisites:** Story 1.2, Story 1.7

**Technical Notes:**
- Soft delete (ARCHIVED status) for audit trail
- Collection naming: `kb_{uuid}`
- Reference: FR9, FR10, FR11, FR14

---

### Story 2.2: Knowledge Base Permissions Backend

As an **administrator**,
I want **to assign users to Knowledge Bases with specific permissions**,
So that **I can control who can read, write, or manage each KB**.

**Acceptance Criteria:**

**Given** I have ADMIN permission on a KB
**When** I call POST /api/v1/knowledge-bases/{id}/permissions
**Then** the specified user is granted the specified permission level
**And** the action is logged to audit.events

**Given** a user has READ permission on a KB
**When** they try to upload a document
**Then** they receive 403 Forbidden

**Given** a user has WRITE permission on a KB
**When** they try to delete the KB
**Then** they receive 403 Forbidden

**Given** a user has no permission on a KB
**When** they try to access it
**Then** they receive 404 Not Found (not 403, to avoid leaking existence)

**And** permission levels are: READ, WRITE, ADMIN
**And** ADMIN includes WRITE includes READ

**Prerequisites:** Story 2.1

**Technical Notes:**
- Permission check middleware on all KB endpoints
- Use 404 for unauthorized access (security through obscurity)
- Reference: FR6, FR7

---

### Story 2.3: Knowledge Base List and Selection Frontend

As a **user**,
I want **to see and switch between Knowledge Bases I have access to**,
So that **I can work with different document collections**.

**Acceptance Criteria:**

**Given** I am logged in
**When** I view the sidebar
**Then** I see a list of Knowledge Bases I have access to
**And** each shows name, document count, and my permission level icon

**Given** multiple KBs exist
**When** I click on a different KB
**Then** it becomes the active KB
**And** the center panel updates to show that KB's context

**Given** I have ADMIN permission
**When** I click "Create Knowledge Base"
**Then** a modal appears with name and description fields
**And** I can create a new KB

**And** the sidebar shows my permission level for each KB:
- ðŸ‘ READ
- âœï¸ WRITE
- âš™ï¸ ADMIN

**Prerequisites:** Story 2.1, Story 1.9

**Technical Notes:**
- Use KBSelectorItem component from UX spec
- Store active KB in Zustand
- Reference: FR12, FR12a, FR13

---

### Story 2.4: Document Upload API and Storage

As a **user with WRITE permission**,
I want **to upload documents to a Knowledge Base**,
So that **they can be processed and made searchable**.

**Acceptance Criteria:**

**Given** I have WRITE permission on a KB
**When** I call POST /api/v1/knowledge-bases/{id}/documents with a file
**Then** the file is uploaded to MinIO (bucket: kb-{id})
**And** a document record is created with status PENDING
**And** an outbox event is created for processing
**And** I receive 202 Accepted with document ID

**And** supported formats are: PDF, DOCX, MD (FR16)
**And** maximum file size is 50MB
**And** the upload is logged to audit.events (FR53)

**Given** I upload an unsupported file type
**When** validation runs
**Then** I receive 400 Bad Request with clear error message

**Prerequisites:** Story 2.2, Story 1.3 (MinIO)

**Technical Notes:**
- Use MinIO Python client
- Chunked upload for large files
- File stored as: `{kb_id}/{doc_id}/{original_filename}`
- Reference: FR15, FR16, FR53

---

### Story 2.5: Document Processing Worker - Parsing

As a **system**,
I want **to parse uploaded documents and extract text**,
So that **content can be chunked and embedded**.

**Acceptance Criteria:**

**Given** a document is in PENDING status
**When** the Celery worker picks up the processing event
**Then** the document status is updated to PROCESSING
**And** the file is downloaded from MinIO
**And** text is extracted using unstructured library

**Given** a PDF document
**When** parsing completes
**Then** text content and page numbers are extracted

**Given** a DOCX document
**When** parsing completes
**Then** text content and section headers are extracted

**Given** a Markdown document
**When** parsing completes
**Then** text content and heading structure are extracted

**Given** parsing fails
**When** max retries (3) are exhausted
**Then** document status is set to FAILED
**And** last_error contains the failure reason

**Prerequisites:** Story 2.4

**Technical Notes:**
- Use unstructured library with appropriate loaders
- Extract metadata: page_number, section_header where available
- Store parsed content temporarily for chunking step
- Reference: FR17

---

### Story 2.6: Document Processing Worker - Chunking and Embedding

As a **system**,
I want **to chunk parsed documents and generate embeddings**,
So that **content can be searched semantically**.

**Acceptance Criteria:**

**Given** a document has been parsed successfully
**When** the chunking step runs
**Then** text is split into semantic chunks (target: 500 tokens, overlap: 50)
**And** each chunk retains metadata (document_id, page, section, char_start, char_end)

**Given** chunks are created
**When** the embedding step runs
**Then** embeddings are generated via LiteLLM
**And** vectors are stored in Qdrant collection (kb_{kb_id})

**And** each Qdrant point includes payload:
- document_id
- document_name
- page_number (if available)
- section_header (if available)
- chunk_text
- char_start, char_end

**Given** all steps complete successfully
**When** the worker finishes
**Then** document status is set to READY
**And** chunk_count is updated on the document record

**Prerequisites:** Story 2.5

**Technical Notes:**
- Use LangChain RecursiveCharacterTextSplitter
- Embedding model configured via LiteLLM (default: text-embedding-ada-002)
- Rich metadata is CRITICAL for citation system
- Reference: FR17, FR43, FR44

---

### Story 2.7: Document Processing Status and Notifications

As a **user**,
I want **to see the status of my uploaded documents**,
So that **I know when they're ready for search**.

**Acceptance Criteria:**

**Given** I uploaded a document
**When** I view the KB document list
**Then** I see the document with its current status:
- PENDING: "Queued for processing"
- PROCESSING: "Processing..." with spinner
- READY: "Ready" with green checkmark
- FAILED: "Failed" with error icon and retry option

**Given** a document finishes processing
**When** status changes to READY or FAILED
**Then** a toast notification appears (if user is on the page)

**Given** a document is READY
**When** I view it in the list
**Then** I see chunk count (e.g., "47 chunks indexed")

**Prerequisites:** Story 2.6, Story 2.3

**Technical Notes:**
- Poll for status updates every 5 seconds while PROCESSING
- Use toast component from shadcn/ui
- Reference: FR18, FR19

---

### Story 2.8: Document List and Metadata View

As a **user**,
I want **to view all documents in a Knowledge Base**,
So that **I can see what content is available**.

**Acceptance Criteria:**

**Given** I have access to a KB
**When** I view the KB detail page
**Then** I see a list of all documents with:
- Document name
- Upload date (relative: "2 hours ago")
- File size
- Uploader name
- Status badge
- Chunk count (if READY)

**And** the list is paginated (20 per page)
**And** I can sort by name, date, or size

**Given** I click on a document
**When** the detail view opens
**Then** I see full metadata including:
- Original filename
- MIME type
- Processing duration
- Last error (if FAILED)

**Prerequisites:** Story 2.7

**Technical Notes:**
- Use date-fns formatDistanceToNow for relative dates
- Reference: FR20, FR21

---

### Story 2.9: Document Upload Frontend

As a **user with WRITE permission**,
I want **to upload documents via drag-and-drop or file picker**,
So that **I can easily add content to a Knowledge Base**.

**Acceptance Criteria:**

**Given** I have WRITE permission on the active KB
**When** I drag a file onto the upload zone
**Then** the zone highlights to indicate drop target
**And** releasing the file starts the upload

**Given** I click the upload zone
**When** the file picker opens
**Then** I can select one or more files
**And** only supported formats are selectable

**Given** upload is in progress
**When** I view the upload zone
**Then** I see a progress bar for each file
**And** I can cancel pending uploads

**Given** upload completes
**When** the response returns
**Then** the document appears in the list with PENDING status
**And** I see a success toast

**Prerequisites:** Story 2.4, Story 2.8

**Technical Notes:**
- Use react-dropzone for drag-and-drop
- Chunked upload for files > 5MB
- Reference: FR15, FR18

---

### Story 2.10: Document Deletion

As a **user with WRITE permission**,
I want **to delete documents from a Knowledge Base**,
So that **I can remove outdated or incorrect content**.

**Acceptance Criteria:**

**Given** I have WRITE permission on a KB
**When** I click delete on a document
**Then** a confirmation dialog appears

**Given** I confirm deletion
**When** the delete request completes
**Then** the document status is set to ARCHIVED
**And** an outbox event is created for cleanup
**And** the action is logged to audit.events

**Given** a document is deleted
**When** the cleanup worker runs
**Then** vectors are removed from Qdrant
**And** file is removed from MinIO
**And** document no longer appears in listings or search results

**Prerequisites:** Story 2.6, Story 2.8

**Technical Notes:**
- Soft delete first (status = ARCHIVED), then async cleanup
- Outbox ensures cleanup completes even if initial request fails
- Reference: FR22, FR23

---

### Story 2.11: Outbox Processing and Reconciliation

As a **system**,
I want **reliable cross-service operations via the outbox pattern**,
So that **document state remains consistent across PostgreSQL, MinIO, and Qdrant**.

**Acceptance Criteria:**

**Given** events exist in the outbox table
**When** the outbox worker runs (every 10 seconds)
**Then** unprocessed events are picked up and executed
**And** processed_at is set on successful completion
**And** attempts is incremented on failure

**Given** an event fails repeatedly
**When** attempts reaches 5
**Then** the event is marked as failed
**And** an alert is logged

**Given** the reconciliation job runs (hourly)
**When** it detects inconsistencies:
- Documents in READY status without vectors
- Vectors without corresponding document records
- Files in MinIO without document records
**Then** it logs the inconsistency and creates correction events

**Prerequisites:** Story 2.6

**Technical Notes:**
- Use Celery Beat for scheduled jobs
- Reconciliation is defensive - logs and alerts, doesn't auto-fix
- Reference: [architecture.md](./architecture.md) Transactional Outbox section

---

### Story 2.12: Document Re-upload and Version Awareness

As a **user with WRITE permission**,
I want **to re-upload an updated version of a document**,
So that **the Knowledge Base stays current**.

**Acceptance Criteria:**

**Given** a document exists in the KB
**When** I upload a file with the same name
**Then** I am prompted: "Replace existing document?"

**Given** I confirm replacement
**When** the upload completes
**Then** the old vectors are removed from Qdrant
**And** the new file replaces the old in MinIO
**And** the document is reprocessed
**And** updated_at timestamp is set

**Given** the replacement is in progress
**When** someone searches
**Then** search uses the old vectors until new processing completes
**And** then atomically switches to new vectors

**Prerequisites:** Story 2.9, Story 2.6

**Technical Notes:**
- Atomic switch: process new vectors, then delete old in single operation
- Consider using versioned point IDs in Qdrant
- Reference: FR23a, FR23b, FR23c

---

## Epic 3: Semantic Search & Citations

**Goal:** Enable users to search their Knowledge Bases with natural language and receive answers with inline citations linking to source documents.

**User Value:** "I can ask questions and get answers with citations I can trust - this is THE magic moment."

**FRs Covered:** FR24-30, FR24a-d, FR27a, FR28a-b, FR29a, FR30a-f, FR43-46, FR54

**Technical Foundation:**
- Qdrant semantic search
- LiteLLM for answer synthesis
- CitationService for source tracking
- SSE for streaming responses

---

### Story 3.1: Semantic Search Backend

As a **user**,
I want **to search my Knowledge Base with natural language**,
So that **I can find relevant information quickly**.

**Acceptance Criteria:**

**Given** I have access to a KB with documents
**When** I call POST /api/v1/search with a query and kb_id
**Then** the query is embedded using the same model as documents
**And** semantic search is performed against Qdrant
**And** top-k results (default: 10) are returned

**And** each result includes:
- document_id, document_name
- chunk_text (the relevant passage)
- page_number, section_header (if available)
- relevance_score (0-1)

**And** the search is logged to audit.events (FR54)

**Given** no relevant results exist
**When** search completes
**Then** empty results array is returned with helpful message

**Prerequisites:** Story 2.6

**Technical Notes:**
- Use langchain-qdrant QdrantVectorStore
- Relevance score from Qdrant distance metric
- Reference: FR24, FR25, FR54

---

### Story 3.2: Answer Synthesis with Citations Backend

As a **user**,
I want **search results synthesized into a coherent answer with citations**,
So that **I get direct answers rather than just document links**.

**Acceptance Criteria:**

**Given** search returns relevant chunks
**When** answer synthesis is requested
**Then** chunks are passed to LLM with citation instructions
**And** LLM generates an answer using [1], [2], etc. markers
**And** CitationService extracts markers and maps to source chunks

**And** the response includes:
- answer_text (with inline citation markers)
- citations array with full metadata per marker
- confidence_score (based on retrieval relevance)

**Given** the LLM response contains [1]
**When** citation extraction runs
**Then** citation 1 maps to the first source chunk used
**And** includes: document_name, page, section, excerpt, char_start, char_end

**And** confidence indicators are calculated based on:
- Retrieval relevance scores
- Number of supporting sources
- Query-answer semantic similarity

**Prerequisites:** Story 3.1

**Technical Notes:**
- System prompt instructs LLM to cite every claim
- CitationService is THE core differentiator - test thoroughly
- Reference: FR26, FR27, FR43, FR44, FR30c

---

### Story 3.3: Search API Streaming Response

As a **user**,
I want **search results to stream in real-time**,
So that **I see answers faster and feel the system is responsive**.

**Acceptance Criteria:**

**Given** I call the search endpoint with stream=true
**When** processing begins
**Then** SSE connection is established
**And** events stream as they're generated:
- `{"type": "status", "content": "Searching..."}`
- `{"type": "token", "content": "OAuth"}` (answer tokens)
- `{"type": "citation", "data": {...}}` (when citation marker parsed)
- `{"type": "done", "confidence": 0.85}`

**Given** streaming is in progress
**When** a citation marker [n] is detected
**Then** a citation event is immediately sent with full metadata
**And** the frontend can display the citation inline

**Given** an error occurs during streaming
**When** the error is caught
**Then** an error event is sent
**And** the connection is closed gracefully

**Prerequisites:** Story 3.2

**Technical Notes:**
- Use FastAPI StreamingResponse with SSE
- Parse tokens as they stream to detect [n] patterns
- Reference: FR35a (applies to search too)

---

### Story 3.4: Search Results UI with Inline Citations

As a **user**,
I want **to see search results with visible inline citations**,
So that **I can trust and verify the answers**.

**Acceptance Criteria:**

**Given** I submit a search query
**When** results stream in
**Then** the answer appears word-by-word in the center panel
**And** citation markers [1], [2] appear inline as blue clickable badges

**Given** an answer is displayed
**When** I view the citations panel (right side)
**Then** I see a card for each citation with:
- Citation number
- Document name
- Page/section reference
- Excerpt preview (truncated)
- "Preview" and "Open" buttons

**And** the confidence indicator shows:
- Green bar (80-100%): High confidence
- Amber bar (50-79%): Medium confidence
- Red bar (0-49%): Low confidence

**And** confidence is ALWAYS shown (FR30c)

**Prerequisites:** Story 3.3, Story 1.9

**Technical Notes:**
- Use CitationMarker and CitationCard components from UX spec
- Use ConfidenceIndicator component
- Reference: FR27a, FR30, FR30c

---

### Story 3.5: Citation Preview and Source Navigation

As a **user**,
I want **to preview and navigate to cited sources**,
So that **I can verify the information without losing context**.

**Acceptance Criteria:**

**Given** an answer has citations displayed
**When** I hover over a citation marker [1]
**Then** a tooltip shows the source title and excerpt snippet

**Given** I click a citation marker
**When** the citation panel scrolls
**Then** the corresponding CitationCard is highlighted

**Given** I click "Preview" on a CitationCard
**When** the preview opens
**Then** I see the cited passage with the relevant text highlighted
**And** I can scroll to see surrounding context

**Given** I click "Open Document"
**When** the document viewer opens
**Then** the full document is shown
**And** it scrolls to and highlights the cited passage (FR28b)

**Prerequisites:** Story 3.4

**Technical Notes:**
- Preview in modal/sheet, document in new tab or full panel
- Use char_start/char_end from citation metadata for highlighting
- Reference: FR28, FR28a, FR28b, FR45

---

### Story 3.6: Cross-KB Search

As a **user**,
I want **to search across all my Knowledge Bases at once**,
So that **I can find information regardless of where it's stored**.

**Acceptance Criteria:**

**Given** I have access to multiple KBs
**When** I search without specifying a KB (default)
**Then** search runs against ALL my permitted KBs
**And** results are merged and ranked by relevance

**And** each result shows which KB it came from
**And** I can filter results by KB after viewing

**Given** I want to search a specific KB
**When** I use the "Search within current KB" filter
**Then** only that KB is searched

**And** cross-KB search is the DEFAULT (FR29a)

**Prerequisites:** Story 3.1, Story 2.2

**Technical Notes:**
- Query multiple Qdrant collections in parallel
- Permission check per collection
- Merge and re-rank results by score
- Reference: FR29, FR29a, FR30e

---

### Story 3.7: Quick Search and Command Palette

As a **user**,
I want **to quickly search via keyboard shortcut**,
So that **I can find information without leaving my current context**.

**Acceptance Criteria:**

**Given** I am anywhere in the application
**When** I press Cmd/Ctrl+K
**Then** a command palette overlay appears
**And** focus is in the search input

**Given** the command palette is open
**When** I type a query and press Enter
**Then** quick search results appear in the palette
**And** I can select a result with arrow keys

**Given** I select a result
**When** I press Enter
**Then** the full search view opens with that result highlighted

**Given** I press Escape
**When** the palette is open
**Then** it closes and focus returns to previous element

**Prerequisites:** Story 3.4

**Technical Notes:**
- Use shadcn/ui Command component (Radix Dialog + cmdk)
- Quick search uses same backend, limited to top 5 results
- Reference: FR24a, FR24b, FR24c

---

### Story 3.8: Search Result Actions

As a **user**,
I want **quick actions on search results**,
So that **I can efficiently work with found information**.

**Acceptance Criteria:**

**Given** a search result is displayed
**When** I view the result card
**Then** I see action buttons:
- "Use in Draft" (prepares for generation)
- "View" (opens document)
- "Similar" (finds similar content)

**Given** I click "Use in Draft"
**When** the action completes
**Then** the result is marked for use in document generation
**And** a badge appears showing "Selected for draft"

**Given** I click "Similar"
**When** the search runs
**Then** results similar to that chunk are displayed
**And** the original query is replaced with "Similar to: [title]"

**Prerequisites:** Story 3.4

**Technical Notes:**
- "Similar" uses the chunk embedding for similarity search
- "Use in Draft" stores selection in session state
- Reference: FR30b

---

### Story 3.9: Relevance Explanation

As a **user**,
I want **to understand WHY a result is relevant**,
So that **I can trust the search quality**.

**Acceptance Criteria:**

**Given** search results are displayed
**When** I view a result card
**Then** I see a "Relevant because:" section explaining:
- Key matching terms/concepts
- Semantic similarity factors
- Source document context

**Given** I want more detail
**When** I expand the explanation
**Then** I see:
- Matching keywords highlighted
- Semantic distance score
- Other documents this relates to

**Prerequisites:** Story 3.4

**Technical Notes:**
- Generate explanation via LLM based on query + chunk
- Cache explanations to avoid repeated LLM calls
- Reference: FR30a

---

### Story 3.10: Verify All Citations

As a **skeptical user**,
I want **to verify all citations in sequence**,
So that **I can systematically check the AI's sources**.

**Acceptance Criteria:**

**Given** an answer has multiple citations
**When** I click "Verify All" button
**Then** verification mode activates
**And** the first citation is highlighted in both answer and panel

**Given** verification mode is active
**When** I click "Next" or press arrow key
**Then** the next citation is highlighted
**And** the preview automatically shows that citation's source

**Given** I verify a citation
**When** I click the checkmark
**Then** a green "Verified" badge appears on that citation
**And** verification progress shows (e.g., "3/7 verified")

**Given** I've verified all citations
**When** I complete the sequence
**Then** "All sources verified" message appears
**And** a summary badge shows on the answer

**Prerequisites:** Story 3.5

**Technical Notes:**
- Track verification state in component state
- Persist verified state for session duration
- Reference: FR30d

---

## Epic 4: Chat & Document Generation

**Goal:** Enable users to have multi-turn conversations and generate document drafts with citations that can be exported.

**User Value:** "I can chat with my knowledge, generate drafts for RFP responses, and export them with citations - the 80% draft in 30 seconds magic moment."

**FRs Covered:** FR31-35, FR35a-b, FR36-42, FR42a-e, FR55

**Technical Foundation:**
- Conversation context management
- LLM streaming with citation tracking
- Document export (DOCX, PDF, MD)
- Generation templates

---

### Story 4.1: Chat Conversation Backend

As a **user**,
I want **to have multi-turn conversations with my Knowledge Base**,
So that **I can explore topics in depth**.

**Acceptance Criteria:**

**Given** I have an active KB
**When** I call POST /api/v1/chat with a message
**Then** the system performs RAG (retrieval + generation)
**And** response includes answer with citations
**And** conversation context is stored in Redis

**Given** I send a follow-up message
**When** the chat endpoint processes it
**Then** previous messages are included as context
**And** the response is contextually aware

**And** conversation context includes:
- Previous messages (up to token limit)
- Retrieved chunks from each turn
- Generated responses

**Prerequisites:** Story 3.2

**Technical Notes:**
- Store conversation in Redis with session key
- Token limit: ~4000 for context, reserve rest for response
- Reference: FR31, FR32

---

### Story 4.2: Chat Streaming UI

As a **user**,
I want **to see chat responses stream in real-time**,
So that **the conversation feels natural and responsive**.

**Acceptance Criteria:**

**Given** I am in the chat interface
**When** I send a message
**Then** my message appears immediately on the right
**And** a "thinking" indicator appears for the AI

**Given** the AI is responding
**When** tokens stream in
**Then** they appear word-by-word in the chat bubble
**And** citation markers appear inline as they're generated
**And** citations populate in the right panel in real-time

**And** user messages have:
- Primary color background
- Right alignment
- Timestamp

**And** AI messages have:
- Surface color background
- Left alignment
- Inline citations
- Confidence indicator

**Prerequisites:** Story 4.1, Story 3.4

**Technical Notes:**
- Use ChatMessage component from UX spec
- SSE for streaming
- Reference: FR35, FR35a, FR35b

---

### Story 4.3: Conversation Management

As a **user**,
I want **to manage my conversation threads**,
So that **I can start fresh or continue previous work**.

**Acceptance Criteria:**

**Given** I am in the chat interface
**When** I click "New Chat"
**Then** a new conversation starts
**And** previous context is cleared

**Given** I have an active conversation
**When** I view the conversation history
**Then** I see all messages from the current session
**And** I can scroll through previous exchanges

**Given** I want to clear history
**When** I click "Clear Chat"
**Then** a confirmation appears
**And** confirming clears all messages
**And** undo is available for 30 seconds

**Prerequisites:** Story 4.2

**Technical Notes:**
- Conversations are session-scoped (not persisted to DB for MVP)
- Reference: FR33, FR34

---

### Story 4.4: Document Generation Request

As a **user**,
I want **to request AI-generated document drafts**,
So that **I can quickly create RFP responses and other artifacts**.

**Acceptance Criteria:**

**Given** I have search results or chat context
**When** I click "Generate Draft"
**Then** a generation modal appears with options:
- Document type dropdown (RFP Response, Checklist, Gap Analysis, Custom)
- Context/instructions textarea
- Source selection (use current results or specify)

**Given** I select document type and add context
**When** I click "Generate"
**Then** generation begins with progress indicator
**And** progress shows which sources are being used
**And** draft streams in with inline citations

**And** the request is logged to audit.events (FR55)

**Prerequisites:** Story 4.1, Story 3.8

**Technical Notes:**
- Document type determines prompt template
- Use selected results from Story 3.8 if available
- Reference: FR36, FR37, FR41, FR55

---

### Story 4.5: Draft Generation Streaming

As a **user**,
I want **to see my draft generate in real-time**,
So that **I can see progress and the draft feels responsive**.

**Acceptance Criteria:**

**Given** generation is in progress
**When** content streams
**Then** the draft appears in an editor panel
**And** citation markers [1], [2] appear inline
**And** a progress bar shows estimated completion

**Given** a section has low confidence
**When** it's generated
**Then** it's highlighted with amber background
**And** a note appears: "Review suggested - lower confidence"

**Given** generation completes
**When** the final token arrives
**Then** "Done" event fires
**And** summary appears: "Draft ready! Based on 5 sources from 3 documents"
**And** all citations are populated in the panel

**Prerequisites:** Story 4.4

**Technical Notes:**
- Use DraftSection component from UX spec
- Confidence calculated per section based on source coverage
- Reference: FR42a, FR42b, FR42e

---

### Story 4.6: Draft Editing

As a **user**,
I want **to edit the generated draft before exporting**,
So that **I can refine and customize the content**.

**Acceptance Criteria:**

**Given** a draft is generated
**When** I click in the draft area
**Then** I can edit the text directly
**And** citation markers remain intact unless deleted

**Given** I'm editing
**When** I delete a citation marker
**Then** it's removed from the text
**And** the citation panel updates accordingly

**Given** I want to regenerate a section
**When** I select text and click "Regenerate"
**Then** that section is regenerated
**And** the rest of the draft is preserved

**Prerequisites:** Story 4.5

**Technical Notes:**
- Use contenteditable or lightweight editor
- Track citation markers as special spans
- Reference: FR39, FR42

---

### Story 4.7: Document Export

As a **user**,
I want **to export my draft in common formats**,
So that **I can use it in my workflow**.

**Acceptance Criteria:**

**Given** a draft exists
**When** I click "Export"
**Then** I see format options: DOCX, PDF, Markdown

**Given** I select DOCX
**When** export completes
**Then** the document downloads
**And** citations appear as footnotes or inline references
**And** formatting is preserved (headers, lists, etc.)

**Given** I select PDF
**When** export completes
**Then** the PDF downloads with proper formatting
**And** citations are rendered appropriately

**Given** I select Markdown
**When** export completes
**Then** the .md file downloads
**And** citations are formatted as [^1] footnotes

**And** before any export, a prompt appears: "Have you verified the sources?" (FR40b)

**Prerequisites:** Story 4.6

**Technical Notes:**
- Use python-docx for DOCX
- Use weasyprint or reportlab for PDF
- Reference: FR40, FR40a, FR40b

---

### Story 4.8: Generation Feedback and Recovery

As a **user**,
I want **to provide feedback when generation doesn't meet my needs**,
So that **I can get better results**.

**Acceptance Criteria:**

**Given** a draft is generated
**When** I'm not satisfied
**Then** I can click "This doesn't look right"
**And** a feedback modal appears

**Given** I provide feedback
**When** I submit
**Then** alternative approaches are offered:
- "Try different sources" (searches again)
- "Use template" (starts from structured template)
- "Regenerate with feedback" (includes my feedback as instruction)

**Given** generation fails
**When** error is detected
**Then** user sees friendly error message
**And** recovery options are presented
**And** they can try again or fall back to template

**Prerequisites:** Story 4.5

**Technical Notes:**
- Log feedback for future improvements
- Reference: FR42c, FR42d

---

### Story 4.9: Generation Templates

As a **user**,
I want **pre-built templates for common document types**,
So that **I can generate consistent, well-structured drafts**.

**Acceptance Criteria:**

**Given** I select a document type
**When** generation starts
**Then** the appropriate template structures the output:

**RFP Response:**
- Executive Summary
- Technical Approach
- Relevant Experience
- Pricing (placeholder)

**Checklist:**
- Numbered requirements
- Status column
- Notes column

**Gap Analysis:**
- Requirement
- Current State
- Gap Identified
- Recommendation

**And** each template section includes citations from relevant sources

**Prerequisites:** Story 4.4

**Technical Notes:**
- Templates as prompt engineering
- Reference: FR37

---

### Story 4.10: Generation Audit Logging

As a **compliance officer**,
I want **all generation requests logged with full context**,
So that **we can audit AI-assisted content creation**.

**Acceptance Criteria:**

**Given** a generation request is made
**When** generation completes (or fails)
**Then** an audit event is logged with:
- user_id
- document_type
- prompt/instructions provided
- source_documents used (list of doc IDs)
- citation_count
- generation_time_ms
- success/failure status

**And** the full generated content is NOT stored in audit (privacy)
**And** source document references ARE stored (provenance)

**Prerequisites:** Story 4.4, Story 1.7

**Technical Notes:**
- Log sources, not content
- Reference: FR55, FR46

---

## Epic 5: Administration & Polish

**Goal:** Provide administrators with system management capabilities and polish the user experience with onboarding and refinements.

**User Value:** "Administrators can fully manage the system, and new users have a delightful onboarding experience."

**FRs Covered:** FR47-52, FR58, FR8a-c, FR12b, FR12c-d

**Technical Foundation:**
- Admin dashboard
- Audit log viewer
- Onboarding wizard
- UX polish items
- **Epic 3 & 4 Integration Completion (NEW - Story 5.0)**
- **Main Application Navigation Menu (NEW - Story 5.17)**
- **Docker E2E Testing Infrastructure (NEW - Story 5.16)**

**Epic 5 Scope Changes:**
- **2025-11-30:** Added Story 5.0: Epic 3 & 4 Integration Completion (CRITICAL)
- **2025-11-30:** Added Story 5.16: Docker E2E Testing Infrastructure (HIGH)
- **2025-12-03:** Added Story 5.17: Main Application Navigation Menu (HIGH)
- **2025-12-05:** Added Stories 5.18-5.20: User/Group/Role Management UI
- **2025-12-05:** Added Story 5.21: Theme System (DONE)
- **2025-12-06:** Added Stories 5.22-5.24: Document Tags, Processing Progress, Dashboard Filtering
- **2025-12-07:** Added Stories 5.25-5.26: Document Chunk Viewer (Backend API + Frontend UI)
- Total stories: 23 (was 21)

---

### Story 5.0: Epic 3 & 4 Integration Completion (CRITICAL - NEW)

As an **administrator and user**,
I want **Epic 3 & 4 features to be accessible through normal UI navigation**,
So that **users can actually use search, chat, and generation features**.

**Priority:** CRITICAL
**Estimated Effort:** 1-2 days
**Owner:** Amelia (Dev) with Winston (Architect) support

**Context:** Epic 4 retrospective (2025-11-30) revealed that while Epic 3 & 4 features are fully implemented with high code quality (95-100/100) and comprehensive test coverage (220+ tests), they are not accessible to users through the UI. This story makes features discoverable and accessible.

**Acceptance Criteria:**

**AC1: Chat Page Route Created**
**Given** chat components exist in `frontend/src/components/chat/`
**When** user navigates to `/app/(protected)/chat`
**Then** a functional chat page renders with ChatContainer component
**And** user can start new conversations, send messages, receive streaming responses

**AC2: Navigation Links Added to Dashboard**
**Given** search and chat features are implemented
**When** user views the dashboard at `/app/(protected)/dashboard`
**Then** navigation cards/buttons for "Search Knowledge Base" and "Chat" are visible
**And** clicking these links navigates to `/search` and `/chat` respectively
**And** "Coming in Epic 3" and "Coming in Epic 4" placeholders are removed

**AC3: Backend Services Verified and Healthy**
**Given** the application depends on multiple backend services
**When** the backend is started
**Then** all required services are running and healthy:
- FastAPI backend, PostgreSQL, Redis, Celery worker, Qdrant, MinIO, LiteLLM

**AC4: Complete User Journeys Smoke Tested**
**Given** all Epic 3 & 4 features are wired into UI
**When** smoke testing is performed
**Then** the following user journeys work end-to-end:
1. Document Upload â†’ Processing â†’ Search
2. Search â†’ Citation Display
3. Chat Conversation (multi-turn)
4. Document Generation (template â†’ draft â†’ export)

**AC5: Navigation Discoverability Validated**
**Given** users should discover features through normal UI flow
**When** a new user logs in for the first time
**Then** Search and Chat features are clearly discoverable from dashboard and command palette

**Prerequisites:** Epic 3 & 4 stories completed (components built, tests passing)

**Technical Notes:**
- Create `/app/(protected)/chat/page.tsx` route
- Update `dashboard/page.tsx` to add Search and Chat navigation cards
- Verify backend services (Celery workers, Qdrant, Redis) are running correctly
- Document service startup process
- **Reference:** [docs/sprint-artifacts/5-0-epic-integration-completion.md](sprint-artifacts/5-0-epic-integration-completion.md)

---

### Story 5.1: Admin Dashboard Overview

As an **administrator**,
I want **to see system-wide statistics at a glance**,
So that **I can monitor system health and usage**.

**Acceptance Criteria:**

**Given** I am logged in as an admin
**When** I navigate to /admin
**Then** I see a dashboard with:
- Total users (active/inactive)
- Total Knowledge Bases
- Total documents (by status)
- Storage usage
- Search queries (last 24h, 7d, 30d)
- Generation requests (last 24h, 7d, 30d)

**And** key metrics have sparkline charts showing trends
**And** I can click any metric to see details

**Prerequisites:** Story 1.6

**Technical Notes:**
- Aggregate queries with caching (refresh every 5 min)
- Reference: FR47

---

### Story 5.2: Audit Log Viewer

As an **administrator**,
I want **to view and filter audit logs**,
So that **I can investigate issues and demonstrate compliance**.

**Acceptance Criteria:**

**Given** I am on the admin audit page
**When** I view the audit log table
**Then** I see events with:
- Timestamp
- User (email)
- Action
- Resource type/ID
- IP address

**And** I can filter by:
- Date range (picker)
- User (autocomplete)
- Action type (dropdown)
- Resource type (dropdown)

**And** results are paginated (50 per page)
**And** I can sort by timestamp (default: newest first)

**Prerequisites:** Story 5.1, Story 1.7

**Technical Notes:**
- Use indexed queries on audit.events
- Reference: FR48

---

### Story 5.3: Audit Log Export

As an **administrator**,
I want **to export audit logs for compliance reporting**,
So that **I can provide evidence to auditors**.

**Acceptance Criteria:**

**Given** I have filtered audit logs
**When** I click "Export"
**Then** I can choose format: CSV or JSON

**Given** I select CSV
**When** export completes
**Then** a CSV file downloads with all filtered records
**And** columns match the table display

**Given** I select JSON
**When** export completes
**Then** a JSON file downloads with full audit event details
**And** includes nested details object

**And** export is limited to 10,000 records (paginate for more)
**And** export action is itself logged to audit

**Prerequisites:** Story 5.2

**Technical Notes:**
- Stream large exports to avoid memory issues
- Reference: FR49

---

### Story 5.4: Processing Queue Status

As an **administrator**,
I want **to monitor the document processing queue**,
So that **I can identify and resolve bottlenecks**.

**Acceptance Criteria:**

**Given** I am on the admin page
**When** I view the queue status section
**Then** I see:
- Queue depth (pending events)
- Currently processing count
- Failed events (last 24h)
- Average processing time

**And** I can see list of failed events with error details
**And** I can manually retry failed events
**And** I can purge completed events older than X days

**Prerequisites:** Story 5.1, Story 2.11

**Technical Notes:**
- Query outbox table for metrics
- Use Celery inspection for worker status
- Reference: FR52

---

### Story 5.5: System Configuration

As an **administrator**,
I want **to configure system-wide settings**,
So that **I can tune the system for our needs**.

**Acceptance Criteria:**

**Given** I am on the admin settings page
**When** I view configuration options
**Then** I can configure:
- Default session timeout
- Maximum upload file size
- Default chunk size for processing
- Rate limits

**Given** I save configuration changes
**When** the save completes
**Then** settings are persisted
**And** affected services pick up new values
**And** the change is logged to audit

**Prerequisites:** Story 5.1

**Technical Notes:**
- Store in database, cache in Redis
- Require service restart for some settings (document)
- Reference: FR50, FR51

---

### Story 5.6: KB Statistics (Admin View)

As an **administrator**,
I want **detailed statistics for each Knowledge Base**,
So that **I can optimize storage and identify issues**.

**Acceptance Criteria:**

**Given** I am viewing a KB as admin
**When** I click "Statistics"
**Then** I see detailed metrics:
- Document count by status
- Total storage size (files + vectors)
- Vector count
- Average chunk size
- Search queries (last 30d)
- Top searchers (users)
- Processing success rate

**And** I can see trends over time (chart)

**Prerequisites:** Story 5.1, Story 2.1

**Technical Notes:**
- Aggregate from PostgreSQL + Qdrant + MinIO
- Reference: FR12b

---

### Story 5.7: Onboarding Wizard

As a **first-time user**,
I want **a guided introduction to LumiKB**,
So that **I understand the value and how to use it**.

**Acceptance Criteria:**

**Given** I login for the first time
**When** the dashboard loads
**Then** the onboarding wizard modal appears

**And** the wizard has steps:
1. "Welcome to LumiKB!" - value proposition
2. "Explore the Sample KB" - guided tour of demo KB
3. "Try a Search" - search the demo KB with suggested query
4. "See the Magic" - highlight citations in results
5. "You're Ready!" - next steps and close

**Given** I complete a step
**When** I click "Next"
**Then** I progress to the next step
**And** progress dots show my position

**Given** I want to skip
**When** I click "Skip Tutorial"
**Then** the wizard closes
**And** my preference is saved (don't show again)

**Prerequisites:** Story 1.10, Story 3.4

**Technical Notes:**
- Use Dialog with step state
- Store onboarding_complete flag on user
- Reference: FR8a, FR8b

---

### Story 5.8: Smart KB Suggestions

As a **user**,
I want **the system to suggest relevant KBs based on my content**,
So that **I can quickly find where to search**.

**Acceptance Criteria:**

**Given** I paste text into the search bar
**When** the system analyzes the content
**Then** it suggests 1-3 most relevant KBs
**And** shows why each is suggested (matching keywords)

**Given** I select a suggested KB
**When** I press Enter
**Then** search runs against that KB

**Given** no strong match exists
**When** analysis completes
**Then** suggestion shows "Search all KBs" as default

**Prerequisites:** Story 3.6

**Technical Notes:**
- Analyze pasted content against KB descriptions + sample docs
- Use lightweight embedding comparison
- Reference: FR12c

---

### Story 5.9: Recent KBs and Polish Items

As a **user**,
I want **quick access to recently used KBs and a polished UI**,
So that **my daily workflow is efficient**.

**Acceptance Criteria:**

**Given** I open the KB sidebar
**When** I view the list
**Then** "Recent" section shows my last 5 accessed KBs
**And** they're ordered by most recent first

**And** additional polish items:
- Loading skeletons on all data-fetching views
- Empty states with helpful messages and CTAs
- Error boundaries with friendly recovery options
- Keyboard navigation throughout (Tab, Enter, Escape)
- Tooltips on icon-only buttons

**Prerequisites:** Story 2.3

**Technical Notes:**
- Track recent KBs in localStorage
- Reference: FR12d
- Reference: UX spec Section 7 - Pattern Decisions

---

### Story 5.10: Command Palette Test Coverage Improvement (Technical Debt)

As a **developer**,
I want **to achieve 100% test coverage for the command palette component**,
So that **we have comprehensive test validation for the quick search feature**.

**Acceptance Criteria:**

**Given** the command palette tests currently have 70% pass rate (7/10)
**When** I investigate the test failures
**Then** I identify the root cause (Command component filtering with mocked data)

**And When** I implement a fix
**Then** all 10 command palette tests pass consistently
**And** tests properly validate:
- Result fetching after debounce
- Result display with metadata
- Error state handling on API failure

**And** I document the chosen approach in test file comments

**Prerequisites:** Story 3.7 (completed)

**Technical Notes:**
- **Current Status:** 7/10 tests passing, 3 tests timeout due to shadcn/ui Command component's internal filtering not working with mocked fetch responses
- **Production Impact:** None - production code is verified correct through passing tests and manual validation
- **Priority:** Low - polish item, not blocking
- **Effort:** 1-2 hours
- **Possible Solutions:**
  1. Mock at component level rather than fetch level
  2. Use real Command component behavior with test data
  3. Convert to E2E tests instead of unit tests
  4. Investigate Command/cmdk library test utilities
- **Reference:** Story 3.7 code review, validation-report-3-7-2025-11-26.md
- **Type:** Technical Debt - Test Infrastructure

---

### Story 5.11: Epic 3 Search Hardening (Technical Debt)

As a **developer**,
I want **to complete deferred test coverage and accessibility work from Epic 3**,
So that **search features have comprehensive test coverage and full WCAG 2.1 AA compliance**.

**Acceptance Criteria:**

**Given** Epic 3 deferred work tracked in epic-3-tech-debt.md
**When** I implement the hardening tasks
**Then** all deferred items are completed:

1. **Backend Unit Tests (TD-3.8-1):**
   - Add `test_similar_search_uses_chunk_embedding()` to test_search_service.py
   - Add `test_similar_search_excludes_original()` to test_search_service.py
   - Add `test_similar_search_checks_permissions()` to test_search_service.py
   - All 3 tests pass

2. **Hook Unit Tests (TD-3.8-2):**
   - Create `frontend/src/lib/stores/__tests__/draft-store.test.ts`
   - Add `test_addToDraft__adds_result_to_store()`
   - Add `test_removeFromDraft__removes_by_id()`
   - Add `test_clearAll__empties_selections()`
   - Add `test_isInDraft__returns_true_when_exists()`
   - Add `test_persistence__survives_page_reload()`
   - All 5 tests pass

3. **Screen Reader Verification (TD-3.8-3):**
   - Manually test with NVDA or JAWS screen reader
   - Verify action buttons announce labels correctly
   - Verify draft selection panel announces count changes
   - Verify similar search flow is navigable
   - Document findings in validation-report-3-8-accessibility.md

4. **Command Palette Dialog Accessibility (TD-3.7-1) - NEW:**
   - Add DialogTitle to command-palette.tsx (wrap with VisuallyHidden)
   - Add DialogDescription with "Search across your knowledge bases"
   - Verify Radix UI accessibility warnings eliminated
   - Test with screen reader to confirm announcements

5. **Command Palette Test Fixes (TD-3.7-2) - OPTIONAL:**
   - Debug and fix 3 failing tests (debounce, metadata, error state)
   - Investigate msw mock handler registration
   - Verify React Query cache state in tests
   - All command palette tests passing (10/10)

6. **Desktop Hover Reveal (TD-3.8-4) - OPTIONAL:**
   - Implement hover reveal for action buttons on desktop (â‰¥1024px)
   - Buttons hidden by default, appear on card hover
   - Mobile/tablet behavior unchanged (always visible)

7. **TODO Cleanup (TD-3.8-5):**
   - Scan search components for TODO comments
   - Resolve or convert to tracked issues
   - Verify 0 TODO comments in search/ directory

**And** all existing tests continue to pass (regression protection)

**Prerequisites:** Story 3.8, 3.7, 3.10 (completed)

**Technical Notes:**
- **Source:** Stories 3-7, 3-8, 3-10 code review deferred items
- **Priority:** Medium (improves quality, not blocking production)
- **Effort:** ~6-7 hours (original 4.5h + 0.5h dialog a11y + 1-2h optional tests)
- **Test Pyramid Goal:** Unit tests strengthen isolation, reduce integration test dependency
- **Accessibility Goal:** WCAG 2.1 AA compliance verification (manual + automated)
- **Reference:** docs/sprint-artifacts/epic-3-tech-debt.md
- **Type:** Technical Debt - Test Coverage & Accessibility
- **Updated:** 2025-11-26 (added TD-3.7-1, TD-3.7-2)

**Task Breakdown:**
- Task 1: Backend unit tests (2h)
- Task 2: Hook unit tests (1.5h)
- Task 3: Screen reader testing (1h)
- Task 4: Dialog accessibility (0.5h) - **NEW**
- Task 5: Command palette tests (1-2h) - OPTIONAL
- Task 6: Desktop hover reveal (0.5h) - OPTIONAL
- Task 7: TODO cleanup (0.5h)

**Note:** TD-3.10-1 (VerifyAllButton test harness issue) deferred to Epic 6 due to low priority (test-only issue, component works in production).

---

### Story 5.12: ATDD Integration Tests Transition to GREEN (Technical Debt)

As a **developer**,
I want **to transition 31 ATDD integration tests from RED phase to GREEN**,
So that **search feature integration tests validate against real indexed data in Qdrant**.

**Acceptance Criteria:**

**Given** 31 integration tests are in ATDD RED phase (intentionally failing)
**When** I implement the test infrastructure improvements
**Then** all 31 tests transition to GREEN:

1. **Test Fixture Helper:**
   - Create `backend/tests/helpers/indexing.py`
   - Implement `wait_for_document_indexed(doc_id, timeout=30)` helper
   - Helper polls Qdrant until document chunks indexed
   - Raises TimeoutError if indexing not complete within timeout

2. **Update Test Fixtures:**
   - Update `test_cross_kb_search.py` (9 tests) - use wait_for_document_indexed()
   - Update `test_llm_synthesis.py` (6 tests) - use wait_for_document_indexed()
   - Update `test_quick_search.py` (5 tests) - use wait_for_document_indexed()
   - Update `test_sse_streaming.py` (6 tests) - use wait_for_document_indexed()
   - Update `test_similar_search.py` (5 tests) - use wait_for_document_indexed()

3. **Test Execution:**
   - Run `make test-backend` - 0 failures, 0 errors
   - All 31 previously RED tests now GREEN
   - Existing 496 passing tests still pass (no regressions)

4. **Documentation:**
   - Update epic-3-tech-debt.md TD-ATDD section with RESOLVED status
   - Document wait_for_document_indexed() usage in testing-framework-guideline.md

**And** tests validate against real Qdrant/LiteLLM integration (not mocks)

**Prerequisites:**
- Epic 2 complete (document processing pipeline functional)
- Story 3.10 complete (all search features implemented)

**Technical Notes:**
- **Source:** TD-ATDD in epic-3-tech-debt.md (lines 186-285)
- **Root Cause:** Tests written before implementation (ATDD), expect indexed documents
- **Current Status:** 26 failed + 5 errors = 31 tests in RED phase
- **Error Pattern:** `assert 500 == 200` (empty Qdrant collections â†’ 500 errors)
- **Priority:** Medium (blocks test confidence, not production)
- **Effort:** 3-4 hours
- **Type:** Technical Debt - Test Infrastructure

**Implementation Strategy:**
1. Create polling helper that checks Qdrant for chunk count > 0
2. Use helper in test setup after document upload
3. Ensure tests use same document fixtures consistently
4. Consider adding test-specific Qdrant collection cleanup

**Affected Tests by Story:**
- Story 3.6 (Cross-KB Search): 9 tests
- Story 3.2 (LLM Synthesis): 6 tests
- Story 3.7 (Quick Search): 5 tests
- Story 3.3 (SSE Streaming): 6 tests
- Story 3.8 (Similar Search): 5 tests

**Validation:**
```bash
make test-backend
# Expected: 527 passed, 9 skipped, 0 failed, 0 errors
```

**Reference:**
- docs/sprint-artifacts/epic-3-tech-debt.md (TD-ATDD section)
- Test design checklist: docs/sprint-artifacts/atdd-checklist-3.*.md

**Note:** This resolves the ATDD RED phase deliberately created during Epic 3 story implementation.

---

### Story 5.13: Celery Beat Filesystem Fix (Technical Debt)

As a **developer**,
I want **to fix the celery-beat read-only filesystem error**,
So that **scheduled tasks (like outbox reconciliation) run reliably**.

**Acceptance Criteria:**

**Given** celery-beat service is restarting with error:
```
OSError: [Errno 30] Read-only file system: 'celerybeat-schedule'
```

**When** I investigate the issue
**Then** I identify the root cause (celerybeat-schedule file location)

**And When** I implement the fix
**Then** celery-beat service runs without restarts:
- `docker compose ps` shows lumikb-celery-beat status as "Up" (not "Restarting")
- No OSError in `docker compose logs celery-beat --tail 50`
- Scheduled tasks execute correctly (verify via logs)

**And** the fix persists across:
- Container restarts
- `docker compose down && docker compose up`
- Full environment rebuild

**Acceptance Validation:**
1. Start services: `docker compose up -d`
2. Wait 2 minutes
3. Check status: `docker compose ps celery-beat` â†’ STATUS = "Up"
4. Check logs: `docker compose logs celery-beat --tail 50` â†’ No "Read-only file system" errors
5. Verify scheduled tasks: Check for outbox processing task executions in logs

**Prerequisites:** Epic 2 complete (celery workers functional)

**Technical Notes:**
- **Root Cause:** celerybeat-schedule file written to read-only container path
- **Current Impact:** Scheduled tasks (e.g., outbox reconciliation every 5 min) may not run
- **Priority:** Medium (doesn't block features, but affects background jobs)
- **Effort:** 1 hour
- **Type:** Technical Debt - Infrastructure

**Possible Solutions:**
1. Configure CELERY_BEAT_SCHEDULE_FILENAME to writable volume
2. Mount /app/celerybeat-schedule as Docker volume
3. Set celery beat to use persistent database backend (Django DB scheduler)
4. Write schedule file to /tmp (ephemeral but functional)

**Recommended Approach:**
Option 1 - Configure persistent volume in docker-compose.yml:
```yaml
celery-beat:
  volumes:
    - celery-beat-schedule:/app/celery-schedule
volumes:
  celery-beat-schedule:
```

**And** update celery config:
```python
# backend/app/workers/celery_app.py
app.conf.beat_schedule_filename = '/app/celery-schedule/celerybeat-schedule'
```

**Validation Files:**
- infrastructure/docker/docker-compose.yml (volume mount)
- backend/app/workers/celery_app.py (config change)

**Reference:**
- Discovered during Epic 3 test analysis (2025-11-26)
- Related to Story 2.11 (outbox reconciliation scheduling)

**Note:** While this doesn't block MVP, it should be fixed before production to ensure reliable background job execution.

---

### Story 5.14: Search Audit Logging (moved from Epic 3)

As a **compliance officer**,
I want **all search queries logged**,
So that **we can audit information access**.

**Acceptance Criteria:**

**Given** a user performs a search
**When** results are returned
**Then** an audit event is logged with:
- user_id
- query text
- kb_ids searched
- result_count
- timestamp
- response_time_ms

**Given** audit logs exist
**When** an admin queries them
**Then** they can filter by user, date, and KB

**And** audit write is async (doesn't block search response)

**Prerequisites:**
- Story 3.1 (Semantic Search Backend) - âœ… Complete
- Story 1.7 (Audit Logging Infrastructure) - âœ… Complete
- Story 5.2 (Audit Log Viewer) - Provides UI to view these logs

**Technical Notes:**
- Reuse audit infrastructure from Story 1.7
- Log to `audit.events` table with action_type = 'search'
- Include search metadata in details JSON column
- Async write via background task (don't block search response)
- **Reference:** FR54
- **Type:** Feature - Compliance & Audit
- **Effort:** 1-2 hours
- **Originally:** Story 3.11 in Epic 3, moved to Epic 5 for thematic fit

**Story Relationship:**
- Provides search audit data that Story 5.2 (Audit Log Viewer) will display
- Complements Story 4.10 (Generation Audit Logging) for complete audit coverage
- Together with Stories 5.2 and 5.3, completes the full audit workflow:
  1. Log search queries (5.14)
  2. Log generation requests (4.10)
  3. View all audit logs (5.2)
  4. Export audit logs (5.3)

---

### Story 5.15: Epic 4 ATDD Transition to GREEN + Test Hardening (Technical Debt)

As a **developer**,
I want **to transition 47 ATDD tests from Epic 4 (Chat & Generation) from RED phase to GREEN**,
So that **chat and generation features have comprehensive test coverage with validated risk mitigations**.

**Acceptance Criteria:**

**Given** 47 ATDD tests are in RED phase (written before implementation)
**When** I implement the test infrastructure and transition tests
**Then** all high-priority tests transition to GREEN:

1. **Test Fixtures & Factories (7 items):**
   - Create `backend/tests/factories/conversation.py`:
     - `create_conversation()` - Basic conversation factory
     - `create_multi_turn_conversation(turns=5)` - Multi-turn conversations
   - Create `backend/tests/factories/generation.py`:
     - `create_generation_request()` - Generation request factory
     - `create_draft()` - Generated draft with citations and confidence
   - Create `backend/tests/factories/citation.py`:
     - `create_citation(number=1)` - Single citation factory
     - `create_complex_citations(count=10)` - Multiple citations with varying scores
   - Update `conftest.py`:
     - Add `redis_client` fixture (using fakeredis)
   - All factories follow faker pattern with override support

2. **Backend API Tests (22 tests):**
   - `test_chat_conversation.py` (5 tests) - âœ… All pass
   - `test_citation_security.py` (5 tests) - âœ… All pass (SECURITY CRITICAL)
   - `test_document_export.py` (7 tests) - âœ… All pass
   - `test_confidence_scoring.py` (5 tests) - âœ… All pass

3. **Frontend E2E Tests (16 tests):**
   - `chat-conversation.spec.ts` (7 tests) - âœ… All pass
   - `document-generation.spec.ts` (9 tests) - âœ… All pass

4. **Component Tests (9 tests):**
   - `chat-message.test.tsx` (9 tests) - âœ… All pass

5. **Export Validation Helpers:**
   - Install: `python-docx`, `PyPDF2`, `reportlab`
   - Create `backend/tests/helpers/export_validation.py`:
     - `validate_docx_citations(docx_bytes, expected_citations)` - Parse DOCX XML
     - `validate_pdf_citations(pdf_bytes, expected_citations)` - Extract PDF text
   - Use helpers in export tests

6. **Risk Mitigation Validation:**
   - R-001 (Token Limit): 3 tests GREEN âœ…
   - R-002 (Citation Injection): 5 tests GREEN âœ… (SECURITY)
   - R-003 (Streaming Latency): 2 tests GREEN âœ…
   - R-004 (Export Citations): 5 tests GREEN âœ…
   - R-005 (Low Confidence): 6 tests GREEN âœ…

7. **Documentation:**
   - Update `docs/sprint-artifacts/epic-4-tech-debt.md` TD-4.0-1 â†’ RESOLVED
   - Add test execution guide to README or testing-framework-guideline.md

**And** all existing tests continue to pass (no regressions)
**And** run `make test-backend` â†’ 0 failures (all Epic 4 tests GREEN)
**And** run `npm run test:e2e -- e2e/tests/chat/` â†’ 0 failures
**And** run `npm run test` â†’ all component tests pass

**Prerequisites:**
- Epic 4 complete (Stories 4.1-4.10 implemented)
- Story 5.12 complete (Epic 3 ATDD transition - similar pattern)

**Technical Notes:**
- **Source:** TD-4.0-1 in epic-4-tech-debt.md
- **Root Cause:** ATDD tests written before implementation (RED phase)
- **Current Status:** 47 tests in RED phase (intentional)
- **Priority:** HIGH (validates 4 high-risk mitigations)
- **Effort:** 16-20 hours
- **Type:** Technical Debt - Test Infrastructure + Security Validation

**Implementation Strategy:**
1. Start with factories (conversation, generation, citation)
2. Add Redis fixture with fakeredis
3. Implement export validation helpers
4. Run backend tests â†’ debug failures â†’ GREEN
5. Run E2E tests â†’ add missing data-testid attributes â†’ GREEN
6. Run component tests â†’ GREEN
7. Validate all 4 risk mitigations covered

**Affected Tests by Story:**
- Story 4.1 (Chat Conversation): 5 backend + 3 E2E tests
- Story 4.2 (Chat Streaming UI): 2 backend + 4 E2E + 9 component tests
- Story 4.5 (Confidence Scoring): 5 backend + 2 E2E tests
- Story 4.7 (Document Export): 7 backend + 3 E2E tests
- Story 4.3, 4.4, 4.6, 4.8, 4.9, 4.10: Covered by above tests

**Security Focus:**
- Citation injection tests (R-002) are **CRITICAL** - must pass 100%
- Adversarial prompt suite validates system resilience
- Citation validation prevents fake source injection

**Test Execution Commands:**
```bash
# Backend tests
cd backend
pytest tests/integration/test_chat*.py -v
pytest tests/integration/test_citation_security.py -v  # SECURITY
pytest tests/integration/test_document_export.py -v
pytest tests/integration/test_confidence_scoring.py -v

# Frontend E2E
cd frontend
npm run test:e2e -- e2e/tests/chat/

# Component tests
npm run test -- src/components/chat/__tests__/

# All Epic 4 tests
make test-epic-4  # Add this target to Makefile
```

**Validation Checklist:**
- [ ] All 7 factories created and tested
- [ ] Redis fixture working with fakeredis
- [ ] Export validation helpers functional
- [ ] 22 backend API tests GREEN
- [ ] 16 E2E tests GREEN
- [ ] 9 component tests GREEN
- [ ] R-002 (Security) tests passing 100%
- [ ] No regressions in existing tests
- [ ] epic-4-tech-debt.md updated

**Reference:**
- docs/sprint-artifacts/epic-4-tech-debt.md (TD-4.0-1)
- docs/sprint-artifacts/atdd-checklist-epic-4.md (implementation guide)
- docs/sprint-artifacts/test-design-epic-4.md (risk assessment)

**Note:** This resolves the ATDD RED phase deliberately created during Epic 4 story implementation. Follows same pattern as Story 5.12 (Epic 3 ATDD transition).

---

### Story 5.17: Main Application Navigation Menu (HIGH - NEW)

As a **user and administrator**,
I want **a persistent main navigation menu on all protected routes**,
So that **I can easily discover and access all application features including admin tools**.

**Priority:** HIGH
**Estimated Effort:** 1-2 days
**Owner:** Amelia (Dev)

**Context:** Stories 5-1 through 5-6 implemented comprehensive admin features (dashboard overview, audit logs, queue monitoring, system configuration, KB statistics) but these features are not accessible via UI navigation. Users cannot discover or navigate to `/admin`, `/admin/audit`, `/admin/queue`, `/admin/config`, or `/admin/kb-stats` routes. This story adds persistent main navigation to make all features discoverable.

**Problem Statement:** Admin features (Stories 5-1 through 5-6) are built and functional but not accessible via UI navigation. The application currently only has:
- KB sidebar (left side) - for knowledge base selection
- Header with search bar and user menu (top)
- Mobile bottom nav with placeholder buttons (mobile only)

Users cannot access admin routes without manually typing URLs. This is the same pattern identified in Epic 4 retrospective where features were built but not accessible.

**Solution:** Add a persistent main navigation component with:
- Core application links: Dashboard, Search, Chat
- Admin section (permission-gated): Admin Dashboard, Audit Logs, Queue Status, System Config, KB Statistics
- Active route highlighting
- Mobile-responsive design
- Full accessibility compliance (WCAG 2.1 AA)

**Acceptance Criteria:**

**AC-5.17.1: Navigation Structure and Layout**
**Given** a user is logged into any protected route
**When** the page loads
**Then** a persistent main navigation menu is visible
**And** navigation is positioned consistently across all routes
**And** navigation contains two sections: "Core Links" and "Admin" (admin-only)
**And** navigation is responsive (desktop sidebar, mobile bottom nav)
**And** navigation does not interfere with existing three-panel layout (KB sidebar, main content, citations panel)

**Validation:**
- Navigation component renders on all routes: `/dashboard`, `/search`, `/chat`, `/admin/*`
- Desktop breakpoint (â‰¥1024px): Navigation is a vertical sidebar
- Mobile/tablet breakpoint (<1024px): Navigation is a bottom bar with icons
- Layout maintains existing KB sidebar and citations panel

**AC-5.17.2: Core Application Links**
**Given** the main navigation is visible
**When** I view the "Core Links" section
**Then** I see three links: "Dashboard", "Search", "Chat"
**And** each link has an appropriate icon (Home, Search, MessageSquare)
**And** clicking each link navigates to `/dashboard`, `/search`, `/chat` respectively
**And** the active route is highlighted visually

**Validation:**
- All 3 core links present with icons
- Navigation works correctly (Next.js routing)
- Active route has distinct visual styling (background color, bold text)
- Icons match design system (Lucide React icons)

**AC-5.17.3: Admin Section (Permission-Gated)**
**Given** I am logged in as an admin user
**When** I view the main navigation
**Then** I see an "Admin" section below core links
**And** the admin section contains 5 links: "Admin Dashboard", "Audit Logs", "Queue Status", "System Config", "KB Statistics"
**And** each admin link has an appropriate icon
**And** clicking each link navigates to the respective admin route

**Given** I am logged in as a regular (non-admin) user
**When** I view the main navigation
**Then** the "Admin" section is not visible

**Validation:**
- Admin section only visible to users with `role === 'admin'`
- All 5 admin links present with correct routes: `/admin`, `/admin/audit`, `/admin/queue`, `/admin/config`, `/admin/kb-stats`
- Permission check uses `useAuthStore` hook
- Non-admin users cannot see admin navigation (verified via frontend logic)

**AC-5.17.4: User Menu Integration**
**Given** the main navigation includes user controls
**When** I view the navigation on desktop
**Then** the existing user menu (Settings, Logout) is integrated into navigation
**And** user menu positioning is consistent with design system

**Validation:**
- User menu component reused from existing header
- Desktop: User menu at bottom of navigation sidebar
- Mobile: User menu in header (existing behavior preserved)

**AC-5.17.5: Mobile Navigation Behavior**
**Given** I am using a mobile device (width < 1024px)
**When** I view the application
**Then** the main navigation is a bottom bar with icon-only buttons
**And** active route is highlighted
**And** tapping a navigation item navigates to that route
**And** touch targets are at least 44x44px (WCAG 2.1 AA)

**Validation:**
- Mobile breakpoint uses bottom navigation bar
- Icons only (no text labels on mobile)
- Active state visually distinct
- Touch target size compliant

**AC-5.17.6: Accessibility Compliance**
**Given** the main navigation must be accessible
**When** I interact with navigation using keyboard or screen reader
**Then** all navigation items are keyboard accessible (Tab, Enter)
**And** active route is announced to screen readers
**And** navigation has proper ARIA labels and roles
**And** focus indicators are visible
**And** navigation complies with WCAG 2.1 AA standards

**Validation:**
- All links keyboard navigable
- ARIA attributes: `role="navigation"`, `aria-label="Main navigation"`, `aria-current="page"` for active route
- Focus visible on keyboard navigation
- Screen reader testing confirms proper announcements

**Prerequisites:**
- Stories 5-1 through 5-6 completed (admin routes exist)
- Story 5.0 completed (dashboard navigation cards exist as pattern reference)

**Technical Notes:**
- Create `MainNav` component in `frontend/src/components/layout/`
- Integrate into `DashboardLayout` component
- Use `usePathname()` hook for active route detection
- Use `useAuthStore()` for permission checks
- Reuse existing header user menu component
- Follow existing three-panel layout pattern (Story 1.9)
- **Reference:** [docs/sprint-artifacts/5-17-main-navigation.md](sprint-artifacts/5-17-main-navigation.md)
- **Pattern Source:** Story 5.0 Quick Access cards, Epic 4 retrospective learning about integration stories

**Benefits:**
- Admin features (Stories 5-1 to 5-6) become discoverable and accessible
- Consistent navigation across entire application
- Improved user experience with clear feature discovery
- Prevents feature abandonment (Epic 4 retrospective learning applied)

---

### Story 5.18: User Management UI (NEW)

As an **administrator**,
I want **to view, create, edit, and manage user accounts through the admin UI**,
So that **I can onboard new team members, update user information, and control account status without direct database access**.

**Priority:** HIGH
**Estimated Effort:** 2-3 days
**Owner:** Amelia (Dev)
**Support:** Winston (Architect)

**Context:** The backend API endpoints for user management exist (GET/POST/PATCH /api/v1/admin/users from Story 1.6), but there is no frontend UI to access these features. Administrators currently have no way to manage users through the application interface.

**Prerequisites:**
- Story 1.6: Admin User Management Backend (DONE)
- Story 5.17: Main Application Navigation Menu (provides admin navigation)

**Acceptance Criteria:**

**AC-5.18.1: User List Page Created**
**Given** I am logged in as an admin (is_superuser=true)
**When** I navigate to /admin/users
**Then** I see a paginated table of all users with columns:
- Email
- Status (Active/Inactive badge)
- Role (Admin/User)
- Created date
- Last active date
**And** I can sort by any column
**And** I can search/filter by email
**And** pagination shows 20 users per page with navigation controls

**AC-5.18.2: Create User Modal Implemented**
**Given** I am on the /admin/users page
**When** I click "Add User" button
**Then** a modal appears with form fields:
- Email (required, validated)
- Password (required, min 8 chars)
- Confirm Password (must match)
- Is Admin checkbox (default unchecked)
**And** clicking "Create" calls POST /api/v1/admin/users
**And** success shows toast notification and refreshes user list
**And** error displays validation message inline

**AC-5.18.3: Edit User Functionality Implemented**
**Given** I am viewing the user list
**When** I click the edit action on a user row
**Then** a modal appears with:
- Email (read-only, displayed for context)
- Status toggle (Active/Inactive)
- Role dropdown (User/Admin)
**And** changes are saved via PATCH /api/v1/admin/users/{user_id}
**And** success shows confirmation and updates table row
**And** I cannot deactivate my own account (prevented with warning)

**AC-5.18.4: User Status Toggle Works**
**Given** I am viewing the user list
**When** I toggle a user's status from Active to Inactive
**Then** the status badge updates immediately (optimistic UI)
**And** the API call updates is_active field
**And** deactivated users cannot log in until reactivated
**And** action is logged to audit.events

**AC-5.18.5: Admin Navigation Updated**
**Given** I am an admin user
**When** I view the admin navigation menu
**Then** I see a "Users" link in the admin section
**And** clicking it navigates to /admin/users
**And** the link shows active state when on users page

**AC-5.18.6: Access Control Enforced**
**Given** I am NOT an admin (is_superuser=false)
**When** I attempt to access /admin/users directly
**Then** I am redirected to /dashboard with an error message
**And** API calls return 403 Forbidden

**Technical Notes:**
- Frontend: Create `/admin/users/page.tsx`, `useUsers` hook, `UserTable`, `CreateUserModal`, `EditUserModal` components
- Use existing backend endpoints: GET/POST/PATCH /api/v1/admin/users
- Add DELETE endpoint to backend if needed (soft delete via is_active=false preferred)
- Reference: FR5, FR56 (audit logging)

**Tasks:**
- Task 1: Create useUsers React Query hook with pagination
- Task 2: Create UserTable component with sorting/filtering
- Task 3: Create CreateUserModal with form validation
- Task 4: Create EditUserModal with status toggle
- Task 5: Create /admin/users/page.tsx
- Task 6: Update main-nav.tsx with Users link
- Task 7: Write unit tests for components
- Task 8: Write integration tests for API calls

---

### Story 5.19: Group Management (NEW)

As an **administrator**,
I want **to create user groups and assign users to groups**,
So that **I can manage KB access permissions at the group level rather than individually per user**.

**Priority:** MEDIUM
**Estimated Effort:** 3-4 days
**Owner:** Amelia (Dev)
**Support:** Winston (Architect)

**Context:** Currently KB permissions are only assignable at the user level. Groups enable bulk permission management - assign KB access to a group, then add/remove users from the group. This is essential for enterprise deployments with many users.

**Prerequisites:**
- Story 5.18: User Management UI
- Story 2.2: Knowledge Base Permissions Backend (DONE)

**Acceptance Criteria:**

**AC-5.19.1: Group Model and API Created**
**Given** the backend needs group management
**When** the migration is applied
**Then** a `groups` table exists with columns:
- id (UUID, PK)
- name (VARCHAR, unique)
- description (TEXT, nullable)
- created_at, updated_at timestamps
**And** a `user_groups` junction table exists (user_id, group_id)
**And** API endpoints exist:
- GET /api/v1/admin/groups (list all)
- POST /api/v1/admin/groups (create)
- PATCH /api/v1/admin/groups/{id} (update)
- DELETE /api/v1/admin/groups/{id} (soft delete)
- POST /api/v1/admin/groups/{id}/members (add users)
- DELETE /api/v1/admin/groups/{id}/members/{user_id} (remove user)

**AC-5.19.2: Group List Page Created**
**Given** I am logged in as an admin
**When** I navigate to /admin/groups
**Then** I see a table of all groups with:
- Name
- Description
- Member count
- Created date
**And** I can search by group name
**And** clicking a row expands to show member list

**AC-5.19.3: Create/Edit Group Modal Implemented**
**Given** I am on the /admin/groups page
**When** I click "Create Group" or edit action
**Then** a modal appears with:
- Name (required, unique)
- Description (optional)
**And** validation prevents duplicate group names
**And** success refreshes group list

**AC-5.19.4: Group Membership Management Implemented**
**Given** I am viewing a group's details
**When** I click "Manage Members"
**Then** I see:
- Current members list with remove action
- "Add Members" button opening user picker
**And** I can search users by email in the picker
**And** adding/removing users updates immediately
**And** changes are logged to audit.events

**AC-5.19.5: Admin Navigation Updated**
**Given** I am an admin user
**When** I view the admin navigation
**Then** I see a "Groups" link
**And** clicking it navigates to /admin/groups

**Technical Notes:**
- Create alembic migration for groups and user_groups tables
- GroupService for business logic
- Consider LDAP/SSO group sync for future (out of scope for MVP)
- Reference: FR6, FR56

**Tasks:**
- Task 1: Create groups and user_groups database models
- Task 2: Create alembic migration
- Task 3: Create GroupService with CRUD operations
- Task 4: Create group API endpoints
- Task 5: Create useGroups React Query hook
- Task 6: Create GroupTable and GroupMembershipModal components
- Task 7: Create /admin/groups/page.tsx
- Task 8: Update navigation
- Task 9: Write backend unit tests
- Task 10: Write frontend tests

---

### Story 5.20: Role & KB Permission Management UI (NEW)

As an **administrator**,
I want **to assign Knowledge Base permissions to users and groups through the UI**,
So that **I can control who can access which Knowledge Bases without SQL queries**.

**Priority:** MEDIUM
**Estimated Effort:** 2-3 days
**Owner:** Amelia (Dev)
**Support:** Winston (Architect)

**Context:** KB permissions backend exists (Story 2.2), but there's no UI to manage permissions. Admins need to assign Read/Write/Admin permissions to users or groups for each KB.

**Prerequisites:**
- Story 5.18: User Management UI
- Story 5.19: Group Management
- Story 2.2: Knowledge Base Permissions Backend (DONE)

**Acceptance Criteria:**

**AC-5.20.1: KB Permission Tab Added**
**Given** I am an admin viewing KB details
**When** I click the "Permissions" tab
**Then** I see two sections:
- User Permissions (table of user-KB-permission assignments)
- Group Permissions (table of group-KB-permission assignments)
**And** each row shows: Entity (user email/group name), Permission Level (Read/Write/Admin)

**AC-5.20.2: Add Permission Modal Implemented**
**Given** I am on the KB Permissions tab
**When** I click "Add User Permission" or "Add Group Permission"
**Then** a modal appears with:
- Entity picker (user email autocomplete or group dropdown)
- Permission level dropdown (Read, Write, Admin)
**And** validation prevents duplicate assignments
**And** success adds row to permissions table

**AC-5.20.3: Edit/Remove Permission Works**
**Given** I am viewing KB permissions
**When** I click edit on a permission row
**Then** I can change the permission level
**And** I can remove the permission entirely
**And** removing the last Admin permission shows warning
**And** changes are saved via API and logged to audit

**AC-5.20.4: Group Permission Inheritance Displayed**
**Given** a user belongs to a group with KB access
**When** I view that user's effective permissions
**Then** I see both direct and inherited (via group) permissions
**And** inherited permissions show "via [Group Name]" indicator
**And** direct permissions override group permissions

**AC-5.20.5: Backend API Extended for Groups**
**Given** groups can now have KB permissions
**When** POST /api/v1/knowledge-bases/{kb_id}/permissions is called
**Then** it accepts both user_id and group_id (mutually exclusive)
**And** GET endpoint returns both user and group permissions
**And** permission checks consider group membership

**AC-5.20.6: Admin Navigation Updated**
**Given** the existing KB management exists
**When** admin views a KB
**Then** "Permissions" is a visible tab option

**Technical Notes:**
- Extend kb_permissions table or create kb_group_permissions
- Update KBPermissionService to check group membership
- Consider permission caching for performance
- Reference: FR6, FR7, FR56

**Tasks:**
- Task 1: Create kb_group_permissions table and migration
- Task 2: Extend KBPermissionService for group support
- Task 3: Update permission check logic to include groups
- Task 4: Create KBPermissionsTab component
- Task 5: Create AddPermissionModal (user/group variants)
- Task 6: Update KB detail page with Permissions tab
- Task 7: Create useKBPermissions hook
- Task 8: Write backend tests for group permissions
- Task 9: Write frontend component tests

---

### Story 5.16: Docker E2E Testing Infrastructure (HIGH - NEW)

As a **developer and QA engineer**,
I want **a Docker-based E2E testing infrastructure that validates complete user journeys**,
So that **we can test the full stack in a production-like environment and catch integration issues before deployment**.

**Priority:** HIGH
**Estimated Effort:** 2-3 days
**Owner:** Murat (TEA)
**Support:** Winston (Architect), Amelia (Dev)

**Context:** Epic 4 retrospective (2025-11-30) revealed that the test pyramid is incomplete. While unit tests (âœ… 114 total) and integration tests (âœ… 74 backend) provide excellent coverage, E2E tests are missing. This story establishes Docker-based E2E testing infrastructure to validate complete user journeys.

**Test Pyramid Gap:**
- âœ… Unit tests: Excellent coverage (29 backend, 51 frontend component, 34 frontend hook)
- âœ… Integration tests: Good coverage (74 backend API tests)
- âŒ E2E tests: Written but not executed (8 E2E tests exist, no infrastructure to run them)

**Acceptance Criteria:**

**AC1: Docker Compose E2E Environment Created**
**Given** the application requires multiple services for E2E testing
**When** `docker-compose -f docker-compose.e2e.yml up` is executed
**Then** all required services start successfully:
- Frontend (Next.js production build on port 3000)
- Backend (FastAPI on port 8000)
- Celery Worker, PostgreSQL, Redis, Qdrant, MinIO, LiteLLM
**And** all services are accessible from the Playwright container
**And** environment variables are configured for E2E testing

**AC2: Playwright E2E Test Execution Configured**
**Given** Playwright tests exist in `frontend/e2e/tests/`
**When** E2E tests are executed with `npm run test:e2e`
**Then** Playwright runs tests against the Docker environment
**And** tests can navigate to frontend and interact with all services
**And** test results are reported with pass/fail status

**AC3: E2E Test Database Seeding Implemented**
**Given** E2E tests require consistent test data
**When** the E2E environment starts
**Then** the test database is seeded with:
- Test users (admin, regular user)
- Test knowledge bases with permissions
- Indexed test documents (for search/chat tests)
**And** seeding is idempotent (can run multiple times without errors)

**AC4: GitHub Actions CI Integration Configured**
**Given** E2E tests should run in CI/CD pipeline
**When** a pull request is created or pushed to main
**Then** GitHub Actions workflow runs E2E tests
**And** workflow uses `docker-compose.e2e.yml` to spin up environment
**And** workflow reports test results and uploads artifacts (screenshots, videos)
**And** workflow fails if any E2E tests fail

**AC5: E2E Test Suite for Epic 3 & 4 Features Executed**
**Given** Epic 3 & 4 features are now accessible (Story 5.0 completed)
**When** E2E tests run in Docker environment
**Then** the following test suites execute successfully:
- **Epic 3:** Search with citations, citation panel, confidence scoring, command palette
- **Epic 4:** Chat conversation (multi-turn), chat streaming, document generation, draft editing, export, feedback
**And** 15-20 E2E tests pass covering critical paths

**Prerequisites:**
- Story 5.0 completed (Epic 3 & 4 features accessible through UI)
- Docker and Docker Compose installed
- Playwright dependencies installed

**Technical Notes:**
- Create `docker-compose.e2e.yml` with all 8 services (frontend, backend, celery, postgres, redis, qdrant, minio, litellm, playwright)
- Configure Playwright to use Docker environment URLs (`E2E_BASE_URL=http://frontend:3000`)
- Create database seeding script (`backend/seed_e2e.py`)
- Create GitHub Actions workflow (`.github/workflows/e2e-tests.yml`)
- Execute existing E2E tests and add missing ones (target: 15-20 total)
- **Reference:** [docs/sprint-artifacts/5-16-docker-e2e-infrastructure.md](sprint-artifacts/5-16-docker-e2e-infrastructure.md)
- **Type:** Test Infrastructure - E2E Testing

**Benefits:**
- Full-stack integration testing (not just mocked components)
- Consistent environment across dev and CI
- Test against real services (PostgreSQL, Redis, Qdrant, MinIO, LiteLLM)
- Catch integration issues before production deployment
- Validate complete user journeys end-to-end
- Framework for all future E2E testing

**User Journeys to Test:**
1. Document Upload â†’ Processing â†’ Search
2. Search â†’ Citation Display
3. Chat Conversation (multi-turn with history)
4. Document Generation (template â†’ draft â†’ export)

---

### Story 5.21: Theme System (NEW)

As a **user**,
I want **to choose from multiple color themes for the application**,
So that **I can personalize my experience and reduce eye strain**.

**Priority:** LOW
**Estimated Effort:** 0.5 days
**Owner:** Amelia (Dev)
**Status:** DONE

**Context:** Users requested additional theme options beyond the default light/dark toggle. This story adds two new themes (Light Blue, Dark Navy) and converts the simple toggle to a theme selector submenu in the user menu.

**Acceptance Criteria:**

**AC-5.21.1: Two New Themes Added**
**Given** users want theme variety
**When** I open the theme selector
**Then** I see 5 theme options:
- Light (default light theme - Trust Blue)
- Dark (default dark theme)
- Light Blue (soft sky blue tones)
- Dark Navy (deep professional navy)
- System (follow OS preference)
**And** each theme has consistent CSS variables for all UI components

**AC-5.21.2: Theme Selector Submenu Implemented**
**Given** theme selection was previously a simple toggle
**When** I click on my user avatar and open the dropdown
**Then** I see a "Theme" submenu with a palette icon
**And** hovering/clicking shows all 5 theme options
**And** current theme shows a checkmark indicator
**And** selecting a theme immediately applies it

**AC-5.21.3: Theme Persistence Works**
**Given** I select a theme
**When** I refresh the page or return later
**Then** my selected theme is preserved
**And** theme preference is stored in localStorage via Zustand persist

**AC-5.21.4: All UI Components Theme-Consistent**
**Given** a theme is selected
**When** I navigate through the application
**Then** all components (cards, tables, modals, popovers, sidebar) use theme colors
**And** there are no white/mismatched boxes on colored backgrounds
**And** text remains readable with appropriate contrast

**Prerequisites:**
- None (uses existing theme infrastructure)

**Technical Notes:**
- CSS variables in `globals.css` for `.light-blue` and `.dark-navy` classes
- Theme store extended: `type Theme = 'light' | 'dark' | 'light-blue' | 'dark-navy' | 'system'`
- THEMES constant exported for UI display
- User menu updated with DropdownMenuSub for theme selection
- Reference: UX spec, accessibility guidelines (WCAG color contrast)

**Files Modified:**
- `frontend/src/app/globals.css` - Added two new theme classes
- `frontend/src/lib/stores/theme-store.ts` - Extended Theme type, added THEMES constant
- `frontend/src/components/layout/user-menu.tsx` - Added theme selector submenu

---

### Story 5.22: Document Tags (NEW)

As a **knowledge base user with ADMIN or WRITE permission**,
I want **to add tags to documents**,
So that **I can categorize, organize, and filter documents more effectively**.

**Priority:** MEDIUM
**Estimated Effort:** 1-2 days
**Story Points:** 3
**Owner:** Dev
**Status:** DRAFTED

**Context:** LumiKB has a robust tagging system for Knowledge Bases. This story extends the same pattern to documents, enabling document organization, enhanced filtering, and improved search. Tags are stored in the existing `documents.metadata` JSONB column (no migration required).

**Acceptance Criteria:**

**AC-5.22.1: Users can add tags during document upload**
**Given** I am a user with ADMIN or WRITE permission on a KB
**When** I upload a document
**Then** I see an optional "Tags" input field
**And** I can enter tags (comma or Enter to add)
**And** a maximum of 10 tags per document, 50 chars each
**And** tags are saved to document metadata on upload

**AC-5.22.2: Tags are displayed in document list**
**Given** I am viewing the KB dashboard document list
**When** documents have tags
**Then** tags display as badges next to each document
**And** truncated if >3 tags (show "+N more")

**AC-5.22.3: Users with ADMIN/WRITE can edit document tags**
**Given** I have ADMIN or WRITE permission
**When** I click the "Edit tags" button on a document
**Then** a modal opens to add/remove tags
**And** changes save on "Save" click

**AC-5.22.4: Users with READ permission cannot edit tags**
**Given** I have only READ permission
**When** I view documents
**Then** I see tags (read-only)
**And** I do NOT see an "Edit tags" button

**AC-5.22.5: Tags are searchable in document filtering**
**Given** I am on the KB dashboard
**When** I filter by tag name
**Then** matching documents are shown (case-insensitive)

**Prerequisites:**
- None (builds on existing document infrastructure)

**Technical Notes:**
- Tags stored in `documents.metadata.tags` JSONB array
- Follows KB tags pattern (kb-tags-feature-implementation.md)
- PATCH `/documents/{id}/tags` endpoint with permission check
- DocumentTagInput, DocumentEditTagsModal components
- See: docs/sprint-artifacts/5-22-document-tags.md

---

### Story 5.23: Document Processing Progress Screen (NEW)

As a **knowledge base user with ADMIN or WRITE permission**,
I want **to view detailed document processing status**,
So that **I can monitor progress, identify failures, and troubleshoot issues**.

**Priority:** HIGH (PRIORITY)
**Estimated Effort:** 2-3 days
**Story Points:** 8
**Owner:** Dev
**Status:** DRAFTED

**Context:** The current document list shows only basic status (pending/processing/processed/failed). This story provides a detailed processing view showing per-step status (Upload â†’ Parse â†’ Chunk â†’ Embed â†’ Index), errors, and chunk counts. Accessible as a new tab in the KB dashboard.

**Acceptance Criteria:**

**AC-5.23.1: Processing tab visible to ADMIN/WRITE users**
**Given** I am viewing the KB dashboard
**And** I have ADMIN or WRITE permission
**When** the page loads
**Then** I see a "Processing" tab alongside existing tabs
**And** clicking it shows the processing status view

**AC-5.23.2: Processing table with comprehensive filters**
**Given** I am on the Processing tab
**When** the page loads
**Then** I see a filter bar with:
- Document name (text search)
- File type (dropdown)
- Date range (date picker)
- Status (pending/processing/processed/failed)
- Current step (upload/parse/chunk/embed/index)
**And** filters apply immediately (no "Apply" button)

**AC-5.23.3: Per-document step status displayed**
**Given** I view the processing table
**When** documents are listed
**Then** each row shows:
- Document name, file type, upload date
- Overall status (color-coded)
- Current/completed step
- Step progress indicator (5-step pipeline)
- Chunk count (if available)
- "View Details" button

**AC-5.23.4: Processing details modal with step-level info**
**Given** I click "View Details" on a document
**When** the modal opens
**Then** I see detailed step-by-step status:
- Each step: pending/in_progress/completed/failed
- Timestamp for each step
- Error message if step failed
- Retry button for failed steps (if applicable)

**AC-5.23.5: Auto-refresh with 10-second interval**
**Given** I am on the Processing tab
**When** documents are processing
**Then** the table auto-refreshes every 10 seconds
**And** I see a "Last updated" timestamp
**And** I can manually refresh with a button

**AC-5.23.6: READ users cannot access Processing tab**
**Given** I have only READ permission on the KB
**When** I view the dashboard
**Then** I do NOT see the "Processing" tab

**Prerequisites:**
- None (extends existing document infrastructure)

**Technical Notes:**
- Database: Add `processing_steps`, `current_step`, `step_errors` JSONB columns to documents table
- API: GET `/knowledge-bases/{kb_id}/documents/processing`, GET `/documents/{doc_id}/processing-details`
- Frontend: ProcessingTab, DocumentProcessingTable, ProcessingFilterBar, ProcessingDetailsModal
- Auto-refresh: React Query with 10s refetchInterval
- See: docs/sprint-artifacts/5-23-document-processing-progress.md

---

### Story 5.24: KB Dashboard Document Filtering & Pagination (NEW)

As a **knowledge base user**,
I want **to filter and paginate the document list in the KB dashboard**,
So that **I can quickly find specific documents in large knowledge bases**.

**Priority:** MEDIUM
**Estimated Effort:** 1-2 days
**Story Points:** 3
**Owner:** Dev
**Status:** DRAFTED

**Context:** As KBs grow, the document list becomes difficult to navigate. This story applies the same filtering/pagination patterns from Story 5-2 (Audit Log Viewer) to the KB dashboard document list.

**Acceptance Criteria:**

**AC-5.24.1: Document list displays filter bar**
**Given** I am viewing the KB dashboard with an active KB
**When** the page loads
**Then** I see a filter bar with:
- Search (text input for document name)
- Type (dropdown: PDF, DOCX, TXT, etc.)
- Status (dropdown: processed, processing, failed, pending)
- Tags (multi-select, from Story 5-22)
- Date Range (date picker)
- Clear Filters button

**AC-5.24.2: Filters update document list in real-time**
**Given** I have applied filters
**When** I change a filter value
**Then** the document list updates automatically
**And** loading indicator shows during refresh
**And** empty state message if no matches

**AC-5.24.3: Document list is paginated**
**Given** the KB has more than 50 documents
**When** I view the document list
**Then** I see pagination controls:
- Current page indicator (e.g., "Page 1 of 5")
- Previous/Next buttons
- Page size selector (25, 50, 100)
- Total document count

**AC-5.24.4: Filter state persists in URL**
**Given** I have applied filters
**When** I refresh the page or share the URL
**Then** the same filters are applied
**URL format:** `/dashboard?kb=<id>&status=failed&type=pdf&page=2`

**AC-5.24.5: Filter by tags shows matching documents**
**Given** documents have tags (from Story 5-22)
**When** I select tags in the filter
**Then** only documents with ALL selected tags are shown

**Prerequisites:**
- Story 5-22 (Document Tags) - tag filter requires tags

**Technical Notes:**
- Follows Story 5-2 (Audit Log Viewer) filtering/pagination pattern
- URL param sync via useDocumentFilters hook
- Debounced search (300ms) to prevent excessive API calls
- Default 50 items per page
- See: docs/sprint-artifacts/5-24-kb-dashboard-filtering.md

---

### Story 5.25: Document Chunk Viewer - Backend API (NEW)

As a **user or admin**,
I want **API endpoints to retrieve document chunks and stream original document content**,
So that **the frontend can display a split-pane viewer for citation verification**.

**Priority:** HIGH
**Estimated Effort:** 1 day
**Story Points:** 3
**Owner:** Dev
**Status:** TODO

**Context:** Users need to verify that AI-generated citations actually come from source documents. Admins need to inspect document processing quality. This story provides the backend API foundation for the Document Chunk Viewer feature.

**Key Discovery:** The existing architecture already stores:
- Original files in MinIO (PDF, DOCX, MD, TXT preserved)
- Chunk metadata in Qdrant with `char_start`, `char_end`, `page_number`
- Full `chunk_text` in vector payloads

This means minimal backend changes are needed - primarily new endpoints to expose existing data.

**Acceptance Criteria:**

**AC-5.25.1: Chunk retrieval endpoint returns chunks with metadata**
**Given** a document has been processed and indexed
**When** I call `GET /api/v1/documents/{id}/chunks`
**Then** I receive a JSON response containing:
- `chunks`: Array of chunk objects
- `total`: Total number of chunks
- `document_id`: The document UUID
**And** each chunk object contains:
- `chunk_index`: Position in sequence (0-indexed)
- `chunk_text`: Full text content
- `char_start`: Starting character offset in source
- `char_end`: Ending character offset in source
- `page_number`: Page number (PDF only, null for others)
- `paragraph_index`: Paragraph index (DOCX/MD)

**AC-5.25.2: Chunk search filters by text content**
**Given** a document has multiple chunks
**When** I call `GET /api/v1/documents/{id}/chunks?search=authentication`
**Then** only chunks containing "authentication" (case-insensitive) are returned
**And** the `total` reflects the filtered count

**AC-5.25.3: Chunk pagination supports large documents**
**Given** a document has 500+ chunks
**When** I call `GET /api/v1/documents/{id}/chunks?skip=0&limit=50`
**Then** I receive exactly 50 chunks (or fewer if near end)
**And** `total` shows the full count

**AC-5.25.4: Document content endpoint streams original file**
**Given** a document exists in MinIO
**When** I call `GET /api/v1/documents/{id}/content`
**Then** the original file is streamed with correct headers:
- `Content-Type`: Matches original MIME type
- `Content-Disposition`: `inline; filename="original_name.pdf"`
- `Content-Length`: File size in bytes

**AC-5.25.5: DOCX content can be converted to HTML (optional)**
**Given** a DOCX document exists
**When** I call `GET /api/v1/documents/{id}/content?format=html`
**Then** the DOCX is converted to semantic HTML using mammoth
**And** the response `Content-Type` is `text/html`

**AC-5.25.6: Endpoints enforce document access permissions**
**Given** I do not have READ access to a KB
**When** I call chunk or content endpoints
**Then** I receive 403 Forbidden
**Given** the document does not exist
**Then** I receive 404 Not Found

**Prerequisites:**
- Epic 2 complete (document processing pipeline functional)

**Technical Notes:**
- Create ChunkService to query Qdrant for document chunks
- Stream files from MinIO using existing download_file_stream()
- Optional: Add mammoth dependency for DOCXâ†’HTML conversion
- See: docs/sprint-artifacts/5-25-document-chunk-viewer-backend.md

---

### Story 5.26: Document Chunk Viewer - Frontend UI (NEW)

As a **user or admin**,
I want **a split-pane document viewer showing original documents alongside extracted text chunks**,
So that **I can verify AI citations and inspect document processing quality**.

**Priority:** HIGH
**Estimated Effort:** 2-3 days
**Story Points:** 8
**Owner:** Dev
**Status:** TODO

**Context:** This is the frontend implementation for the Document Chunk Viewer feature. It displays original documents (PDF, DOCX, Markdown, Text) alongside extracted chunks with highlighting support.

**Acceptance Criteria:**

**AC-5.26.1: Document detail modal has "View & Chunks" tab**
**Given** I open a document detail modal
**When** the modal renders
**Then** I see tab navigation with "Details" and "View & Chunks" tabs
**And** clicking "View & Chunks" shows the split-pane viewer

**AC-5.26.2: Split-pane layout with resizable panels**
**Given** I am on the "View & Chunks" tab
**When** the viewer loads
**Then** I see a split-pane layout:
- Left panel (60%): Document viewer
- Right panel (40%): Chunk sidebar
**And** I can drag the divider to resize panels
**And** on mobile (<1024px), panels stack vertically

**AC-5.26.3: Chunk sidebar with search and list**
**Given** the chunk sidebar is visible
**When** chunks are loaded
**Then** I see:
- Search box at top
- Chunk count indicator (e.g., "42 chunks")
- Scrollable list of chunk previews

**AC-5.26.4: Chunks expand to full text**
**Given** I see a collapsed chunk
**When** I click on it
**Then** it expands to show full text
**And** other chunks collapse (accordion behavior)
**And** I see a collapse button at bottom-right

**AC-5.26.5: Search filters chunks in real-time**
**Given** I type in the search box
**When** I pause typing (300ms debounce)
**Then** the chunk list filters to show only matching chunks
**And** the chunk count updates

**AC-5.26.6: PDF viewer with page navigation and highlighting**
**Given** I view a PDF document
**When** I click a chunk
**Then** the PDF scrolls to the relevant page
**And** the text is highlighted (yellow overlay)
**And** I can navigate pages with prev/next buttons

**AC-5.26.7: DOCX viewer with paragraph highlighting**
**Given** I view a DOCX document
**When** I click a chunk
**Then** the viewer scrolls to the paragraph
**And** the paragraph is highlighted (yellow background)

**AC-5.26.8: Markdown viewer with character highlighting**
**Given** I view a Markdown document
**When** I click a chunk
**Then** the viewer scrolls to the position
**And** the character range is highlighted

**AC-5.26.9: Text viewer with character highlighting**
**Given** I view a plain text document
**When** I click a chunk
**Then** the viewer scrolls to the line
**And** the character range is highlighted

**AC-5.26.10: Loading, error, and empty states handled**
**Given** the viewer is loading
**Then** I see skeleton placeholders
**Given** an error occurs
**Then** I see an error message with retry button
**Given** a document has no chunks
**Then** I see an empty state message

**Prerequisites:**
- Story 5-25: Document Chunk Viewer - Backend API

**Technical Notes:**
- Dependencies: react-pdf, pdfjs-dist, docx-preview, react-markdown, react-resizable-panels, @tanstack/react-virtual
- PDF.js worker must be configured (CDN or public folder)
- Virtual scroll required for performance with 1000+ chunks
- Blob URLs must be revoked on unmount to prevent memory leaks
- See: docs/sprint-artifacts/5-26-document-chunk-viewer-frontend.md

---

## Epic 6: Document Lifecycle Management

**Goal:** Provide comprehensive document lifecycle management including archive, restore, purge, clear failed, duplicate detection, and replace capabilities.

**User Value:** Users can manage document lifecycle states - archiving completed documents to declutter active views, restoring archived documents when needed, permanently purging documents, clearing failed documents, detecting duplicate uploads, and replacing existing documents with updated versions.

**FRs Covered:** FR59-FR77

**Technical Foundation:**
- Document state machine: pending â†’ processing â†’ completed â†’ archived / failed
- Multi-layer storage operations: PostgreSQL, Qdrant, MinIO, Redis/Celery
- Qdrant soft-filtering via status payload for archived documents
- Transactional operations for replace flow (delete + upload)
- Case-insensitive duplicate name detection within KB scope

---

### Story 6.1: Archive Document Backend

**Description:** As a KB owner or admin, I want to archive completed documents so they are removed from active search results while remaining recoverable.

**Story Points:** 3

**Acceptance Criteria:**

**AC-6.1.1: Archive endpoint exists**
**Given** I am authenticated as KB owner or admin
**When** I call `POST /api/v1/knowledge-bases/{kb_id}/documents/{doc_id}/archive`
**Then** I receive 200 OK
**And** the document status changes from "completed" to "archived"
**And** an audit log entry is created with action "document_archived"

**AC-6.1.2: Only completed documents can be archived**
**Given** a document has status "pending", "processing", or "failed"
**When** I attempt to archive it
**Then** I receive 400 Bad Request with message "Only completed documents can be archived"

**AC-6.1.3: Already archived document returns 400**
**Given** a document is already archived
**When** I attempt to archive it again
**Then** I receive 400 Bad Request with message "Document is already archived"

**AC-6.1.4: Qdrant vectors marked as archived**
**Given** I archive a document
**When** the operation completes
**Then** all Qdrant vectors for this document have payload `status: "archived"`
**And** vectors are not deleted (soft-filter approach)

**AC-6.1.5: Permission check enforced**
**Given** I am not KB owner or admin
**When** I attempt to archive a document
**Then** I receive 403 Forbidden

**AC-6.1.6: Archived documents excluded from search**
**Given** a document is archived
**When** I perform semantic search on the KB
**Then** the archived document's chunks do not appear in results

**Prerequisites:**
- Existing document model with status field
- Qdrant client with payload update capability

**Technical Notes:**
- Add `archived_at` timestamp field to document model
- Qdrant update operation: `qdrant_client.set_payload(collection, {status: "archived"}, filter)`
- Search filter: `must_not: [{key: "status", match: {value: "archived"}}]`

---

### Story 6.2: Restore Document Backend

**Description:** As a KB owner or admin, I want to restore archived documents back to active status so they reappear in search results.

**Story Points:** 3

**Acceptance Criteria:**

**AC-6.2.1: Restore endpoint exists**
**Given** I am authenticated as KB owner or admin
**When** I call `POST /api/v1/knowledge-bases/{kb_id}/documents/{doc_id}/restore`
**Then** I receive 200 OK
**And** the document status changes from "archived" to "completed"
**And** an audit log entry is created with action "document_restored"

**AC-6.2.2: Only archived documents can be restored**
**Given** a document has status other than "archived"
**When** I attempt to restore it
**Then** I receive 400 Bad Request with message "Only archived documents can be restored"

**AC-6.2.3: Name collision blocks restore**
**Given** an archived document named "report.pdf"
**And** an active document with the same name exists in the KB
**When** I attempt to restore the archived document
**Then** I receive 409 Conflict with message "Cannot restore: a document with this name already exists"

**AC-6.2.4: Qdrant vectors restored to active**
**Given** I restore a document
**When** the operation completes
**Then** all Qdrant vectors for this document have payload `status: "completed"`
**And** vectors appear in search results

**AC-6.2.5: Permission check enforced**
**Given** I am not KB owner or admin
**When** I attempt to restore a document
**Then** I receive 403 Forbidden

**AC-6.2.6: archived_at timestamp cleared**
**Given** I restore a document
**When** the operation completes
**Then** the `archived_at` field is set to null

**Prerequisites:**
- Story 6-1: Archive Document Backend

**Technical Notes:**
- Case-insensitive name collision check: `SELECT COUNT(*) FROM documents WHERE kb_id=? AND LOWER(name)=LOWER(?) AND status != 'archived' AND id != ?`
- Qdrant payload update to remove archived status

---

### Story 6.3: Purge Document Backend

**Description:** As a KB owner or admin, I want to permanently delete archived documents including all storage artifacts so I can free up storage and comply with data retention policies.

**Story Points:** 5

**Acceptance Criteria:**

**AC-6.3.1: Single purge endpoint exists**
**Given** I am authenticated as KB owner or admin
**When** I call `DELETE /api/v1/knowledge-bases/{kb_id}/documents/{doc_id}/purge`
**Then** I receive 200 OK
**And** the document is permanently deleted
**And** an audit log entry is created with action "document_purged"

**AC-6.3.2: Bulk purge endpoint exists**
**Given** I am authenticated as KB owner or admin
**When** I call `POST /api/v1/knowledge-bases/{kb_id}/documents/bulk-purge` with `{"document_ids": [...]}`
**Then** I receive 200 OK with count of purged documents
**And** all specified archived documents are permanently deleted
**And** audit log entries are created for each purged document

**AC-6.3.3: Only archived documents can be purged**
**Given** a document has status other than "archived"
**When** I attempt to purge it
**Then** I receive 400 Bad Request with message "Only archived documents can be purged"

**AC-6.3.4: All storage layers cleaned**
**Given** I purge a document
**When** the operation completes
**Then** the document row is deleted from PostgreSQL
**And** all vectors are deleted from Qdrant collection
**And** the file is deleted from MinIO bucket
**And** any pending Celery tasks are revoked

**AC-6.3.5: Permission check enforced**
**Given** I am not KB owner or admin
**When** I attempt to purge a document
**Then** I receive 403 Forbidden

**AC-6.3.6: Bulk purge skips non-archived with partial success**
**Given** a bulk purge request contains both archived and non-archived document IDs
**When** I execute the bulk purge
**Then** only archived documents are purged
**And** response includes `{"purged": 3, "skipped": 2, "skipped_ids": [...]}`

**Prerequisites:**
- Story 6-1: Archive Document Backend

**Technical Notes:**
- Qdrant delete: `qdrant_client.delete(collection, filter={doc_id: doc_id})`
- MinIO delete: `minio_client.remove_object(bucket, object_name)`
- Celery task revocation: `app.control.revoke(task_id, terminate=True)`
- Use database transaction for atomicity

---

### Story 6.4: Clear Failed Document Backend

**Description:** As a KB owner or admin, I want to clear failed documents so I can remove partial artifacts and retry document uploads cleanly.

**Story Points:** 3

**Acceptance Criteria:**

**AC-6.4.1: Clear failed endpoint exists**
**Given** I am authenticated as KB owner or admin
**When** I call `DELETE /api/v1/knowledge-bases/{kb_id}/documents/{doc_id}/clear`
**Then** I receive 200 OK
**And** the failed document and all artifacts are removed
**And** an audit log entry is created with action "document_cleared"

**AC-6.4.2: Only failed documents can be cleared**
**Given** a document has status other than "failed"
**When** I attempt to clear it
**Then** I receive 400 Bad Request with message "Only failed documents can be cleared"

**AC-6.4.3: All partial artifacts cleaned**
**Given** I clear a failed document
**When** the operation completes
**Then** the document row is deleted from PostgreSQL
**And** any partial vectors are deleted from Qdrant
**And** the file is deleted from MinIO (if exists)
**And** any pending/failed Celery tasks are revoked
**And** Redis keys related to the task are cleared

**AC-6.4.4: Permission check enforced**
**Given** I am not KB owner or admin
**When** I attempt to clear a failed document
**Then** I receive 403 Forbidden

**AC-6.4.5: Already processing document cannot be cleared**
**Given** a document has status "processing"
**When** I attempt to clear it
**Then** I receive 400 Bad Request with message "Cannot clear document while processing is in progress"

**Prerequisites:**
- Existing document model with status tracking
- Celery task management capability

**Technical Notes:**
- Query for task_id from document metadata or Celery result backend
- Handle case where some artifacts don't exist (no-op, not error)
- Clear Redis keys: `redis_client.delete(f"celery-task-meta-{task_id}")`

---

### Story 6.5: Duplicate Detection & Auto-Clear Backend

**Description:** As a user uploading documents, I want the system to detect duplicate document names and auto-clear failed documents with the same name so I can re-upload without manual cleanup.

**Story Points:** 5

**Acceptance Criteria:**

**AC-6.5.1: Upload detects duplicate active document**
**Given** I upload a document named "report.pdf" (case-insensitive)
**And** a document with the same name exists with status "completed" or "processing" or "pending"
**When** the upload is processed
**Then** I receive 409 Conflict with response:
```json
{
  "error": "duplicate_document",
  "existing_document_id": "uuid",
  "existing_status": "completed",
  "message": "A document with this name already exists"
}
```

**AC-6.5.2: Upload detects duplicate archived document**
**Given** I upload a document named "report.pdf"
**And** an archived document with the same name exists
**When** the upload is processed
**Then** I receive 409 Conflict with response indicating archived duplicate:
```json
{
  "error": "duplicate_document",
  "existing_document_id": "uuid",
  "existing_status": "archived",
  "message": "An archived document with this name exists"
}
```

**AC-6.5.3: Upload auto-clears failed document**
**Given** I upload a document named "report.pdf"
**And** a failed document with the same name exists
**When** the upload is processed
**Then** the failed document is auto-cleared (artifacts removed)
**And** the new upload proceeds normally
**And** I receive notification in response: `{"auto_cleared_document_id": "uuid", "message": "Previous failed upload was automatically cleared"}`

**AC-6.5.4: Case-insensitive matching**
**Given** a document named "Report.PDF" exists
**When** I upload "report.pdf" or "REPORT.pdf"
**Then** duplicate detection triggers

**AC-6.5.5: Duplicate check scoped to KB**
**Given** a document "report.pdf" exists in KB-A
**When** I upload "report.pdf" to KB-B
**Then** no duplicate is detected
**And** upload proceeds normally

**Prerequisites:**
- Existing document upload endpoint
- Story 6-4: Clear Failed Document Backend (for auto-clear logic)

**Technical Notes:**
- Check query: `SELECT id, status FROM documents WHERE kb_id=? AND LOWER(name)=LOWER(?) LIMIT 1`
- Auto-clear uses same logic as Story 6-4 but triggered automatically
- Audit log: "document_auto_cleared" with reason "duplicate_upload"

---

### Story 6.6: Replace Document Backend

**Description:** As a KB owner or admin, I want to replace an existing document with a new version so I can update content without changing the document's identity in the system.

**Story Points:** 5

**Acceptance Criteria:**

**AC-6.6.1: Replace endpoint exists**
**Given** I am authenticated as KB owner or admin
**And** a document exists (any status except "processing")
**When** I call `POST /api/v1/knowledge-bases/{kb_id}/documents/{doc_id}/replace` with new file
**Then** I receive 200 OK with new document details
**And** an audit log entry is created with action "document_replaced"

**AC-6.6.2: Replace performs atomic delete-then-upload**
**Given** I replace a document
**When** the operation executes
**Then** the old document's vectors are deleted from Qdrant
**And** the old file is deleted from MinIO
**And** the new file is uploaded to MinIO
**And** document metadata is updated (file_size, content_type, updated_at)
**And** document status is set to "pending" for reprocessing

**AC-6.6.3: Replace preserves document ID and metadata**
**Given** I replace a document
**When** the operation completes
**Then** the document ID remains the same
**And** the document name is updated to new file name
**And** created_at timestamp is preserved
**And** tags and other metadata are preserved

**AC-6.6.4: Cannot replace while processing**
**Given** a document has status "processing"
**When** I attempt to replace it
**Then** I receive 400 Bad Request with message "Cannot replace document while processing is in progress"

**AC-6.6.5: Permission check enforced**
**Given** I am not KB owner or admin
**When** I attempt to replace a document
**Then** I receive 403 Forbidden

**AC-6.6.6: Replace triggers reprocessing**
**Given** I replace a document
**When** the operation completes
**Then** a new Celery task is queued for document processing
**And** the document status shows "pending"

**AC-6.6.7: Replace from upload flow with confirmation**
**Given** duplicate detection returns 409 for an active document
**When** user confirms replacement via `POST /api/v1/knowledge-bases/{kb_id}/documents/{doc_id}/replace`
**Then** the existing document is replaced with the new upload

**Prerequisites:**
- Story 6-5: Duplicate Detection Backend
- Existing document upload and processing pipeline

**Technical Notes:**
- Two-phase operation: 1) validate & stage new file, 2) delete old + activate new
- Use database transaction to ensure atomicity
- Preserve document UUID for any external references

---

### Story 6.7: Archive Management UI

**Description:** As a user, I want a dedicated archive page to browse, search, filter, restore, and purge archived documents.

**Story Points:** 5

**Acceptance Criteria:**

**AC-6.7.1: Archive page accessible from navigation**
**Given** I am on any page
**When** I click the "Archive" link in navigation (or KB context menu)
**Then** I see the archive management page
**And** URL is `/archive` or `/knowledge-bases/{kb_id}/archive`

**AC-6.7.2: Archive page lists archived documents**
**Given** I am on the archive page
**Then** I see a table of archived documents with columns:
- Document name
- KB name
- Archived date
- Original completion date
- File size
- Actions (Restore, Purge)

**AC-6.7.3: Pagination consistent with document list**
**Given** there are more than 20 archived documents
**Then** I see pagination controls
**And** default page size is 20
**And** I can change page size (10, 20, 50, 100)

**AC-6.7.4: Search archived documents**
**Given** I am on the archive page
**When** I type in the search box
**Then** results filter by document name (case-insensitive)
**And** search is debounced (300ms)

**AC-6.7.5: Filter by KB**
**Given** I am on the archive page
**When** I select a KB from the filter dropdown
**Then** only archived documents from that KB are shown

**AC-6.7.6: Filter by date range**
**Given** I am on the archive page
**When** I select archived date range
**Then** only documents archived within that range are shown

**AC-6.7.7: Restore action with confirmation**
**Given** I click "Restore" on an archived document
**Then** I see a confirmation dialog: "Restore 'filename.pdf' to active documents?"
**When** I confirm
**Then** the document is restored
**And** success toast appears
**And** document disappears from archive list

**AC-6.7.8: Purge action with two-step confirmation**
**Given** I click "Purge" on an archived document
**Then** I see a warning dialog: "Permanently delete 'filename.pdf'? This cannot be undone."
**When** I confirm
**Then** I see a second confirmation: "Type 'DELETE' to confirm permanent deletion"
**When** I type "DELETE" and confirm
**Then** the document is purged
**And** success toast appears

**AC-6.7.9: Bulk purge with selection**
**Given** I select multiple archived documents via checkboxes
**When** I click "Purge Selected"
**Then** I see bulk purge confirmation with count
**And** two-step confirmation applies

**AC-6.7.10: Restore collision shows error**
**Given** I attempt to restore a document
**And** name collision exists
**When** the API returns 409
**Then** I see error toast: "Cannot restore: a document with this name already exists"

**Prerequisites:**
- Story 6-1, 6-2, 6-3: Backend APIs

**Technical Notes:**
- Use same DataTable component as document list
- API: `GET /api/v1/documents/archived?kb_id=&search=&page=&limit=`
- Loading skeleton during fetch
- Error boundary for failed operations

---

### Story 6.8: Document List Archive/Clear Actions UI

**Description:** As a KB owner or admin, I want archive and clear actions in the document list so I can manage document lifecycle without leaving the KB view.

**Story Points:** 3

**Acceptance Criteria:**

**AC-6.8.1: Archive action in document row menu**
**Given** I am viewing documents in a KB
**And** I am KB owner or admin
**And** a document has status "completed"
**When** I click the document row actions menu (â‹®)
**Then** I see "Archive" option

**AC-6.8.2: Archive action with confirmation**
**Given** I click "Archive" on a completed document
**Then** I see confirmation: "Archive 'filename.pdf'? It will be removed from search results."
**When** I confirm
**Then** the document status changes to "archived"
**And** success toast appears
**And** document row shows "Archived" badge or is removed from list

**AC-6.8.3: Clear action for failed documents**
**Given** a document has status "failed"
**When** I click the document row actions menu
**Then** I see "Clear" option (not "Archive")

**AC-6.8.4: Clear action with confirmation**
**Given** I click "Clear" on a failed document
**Then** I see confirmation: "Clear failed document 'filename.pdf'? All partial data will be removed."
**When** I confirm
**Then** the document is cleared
**And** success toast appears
**And** document row is removed from list

**AC-6.8.5: Actions hidden for non-owners**
**Given** I am not KB owner or admin
**Then** "Archive" and "Clear" actions are not visible in menu

**AC-6.8.6: Action disabled during processing**
**Given** a document has status "processing"
**Then** no lifecycle actions are available
**And** tooltip explains "Cannot modify while processing"

**AC-6.8.7: Bulk archive selection**
**Given** I select multiple completed documents
**Then** "Archive Selected" button appears in toolbar
**When** I click it
**Then** confirmation shows count of documents to archive

**Prerequisites:**
- Story 6-1, 6-4: Backend APIs
- Existing document list component

**Technical Notes:**
- Extend existing DocumentActionsMenu component
- Check permissions via useKBPermissions hook
- Optimistic UI update with rollback on error

---

### Story 6.9: Duplicate Upload & Replace UI

**Description:** As a user, I want clear feedback when uploading duplicate documents and the ability to replace existing documents through the UI.

**Story Points:** 3

**Acceptance Criteria:**

**AC-6.9.1: Duplicate detection modal appears**
**Given** I upload a document
**And** the API returns 409 duplicate_document
**Then** I see a modal with:
- Document name
- Existing document status (completed/archived)
- Options: "Cancel" / "Replace Existing"

**AC-6.9.2: Replace option for active documents**
**Given** duplicate modal shows for a "completed" document
**When** I click "Replace Existing"
**Then** I see two-step confirmation: "This will delete the existing document and upload the new version. Continue?"
**When** I confirm
**Then** replace API is called
**And** progress indicator shows
**And** success message on completion

**AC-6.9.3: Archived duplicate shows restore suggestion**
**Given** duplicate modal shows for an "archived" document
**Then** I see message: "An archived document with this name exists"
**And** options: "Cancel" / "Restore Existing" / "Replace Archived"

**AC-6.9.4: Auto-clear notification for failed**
**Given** I upload a document
**And** the API auto-cleared a failed document
**Then** I see info toast: "Previous failed upload 'filename.pdf' was automatically cleared"
**And** upload proceeds normally

**AC-6.9.5: Cancel returns to normal state**
**Given** I see duplicate modal
**When** I click "Cancel"
**Then** modal closes
**And** no changes are made
**And** I can retry with a different file

**AC-6.9.6: Replace progress and error handling**
**Given** replace is in progress
**Then** I see progress indicator (spinner)
**And** upload button is disabled
**Given** replace fails
**Then** I see error toast with message
**And** original document is unchanged

**AC-6.9.7: Name collision on restore shows clear message**
**Given** I choose "Restore Existing" for archived duplicate
**And** restore fails due to name collision
**Then** I see error: "Cannot restore: rename the archived document first or delete the conflicting active document"

**Prerequisites:**
- Story 6-5, 6-6: Backend APIs
- Existing document upload component

**Technical Notes:**
- Intercept 409 response in upload mutation
- DuplicateDocumentModal component with state machine
- Use same upload progress component for replace operation

---

## Epic 7: Infrastructure & DevOps

**Goal:** Establish DevOps infrastructure, testing automation, centralized configuration, model management, and deployment tooling to support production operations.

**User Value:** Development team has reliable CI/CD pipelines, comprehensive E2E testing, centralized model management, and production-ready deployment infrastructure. Users can leverage multiple LLM providers with per-KB configuration.

**FRs Covered:** Infrastructure-focused (no direct FR mapping - supports all FRs operationally)

**Technical Foundation:**
- Docker-based E2E testing with Playwright
- GitHub Actions CI/CD pipelines
- Kubernetes/Helm production deployment
- Prometheus/Grafana observability stack
- LLM Model Registry with multi-provider support
- Per-KB model configuration with Qdrant collection auto-creation

---

### Story 7.1: Docker E2E Infrastructure

**Description:** As a developer, I want Docker-based E2E testing infrastructure so I can run comprehensive integration tests against the full stack.

**Story Points:** 5

**Migrated From:** Story 5-16 (scope reduced - E2E automation moved to Story 8.16)

**Acceptance Criteria:**
(See specification at docs/sprint-artifacts/7-1-docker-e2e-infrastructure.md)

**Prerequisites:** None

**Technical Notes:**
- docker-compose.e2e.yml with all 8 services
- Service health checks and dependencies
- Database seeding for E2E tests (idempotent)
- Infrastructure verification

**Deferred to Story 8.16:**
- Playwright Docker configuration
- GitHub Actions E2E workflow
- E2E test execution

---

### Story 7.2: Centralized LLM Configuration

**Description:** As an admin, I want centralized LLM configuration management so I can switch between model providers without code changes.

**Story Points:** 5

**Acceptance Criteria:**

**AC-7.2.1: Admin UI for model configuration**
**Given** I am logged in as admin
**When** I navigate to Admin > System Config
**Then** I see LLM model settings with current values

**AC-7.2.2: Model switching without restart**
**Given** I update the LLM model configuration
**When** I save changes
**Then** new requests use the updated model
**And** no service restart is required (hot-reload)

**AC-7.2.3: Embedding model dimension validation**
**Given** I switch to a different embedding model
**When** the dimensions differ from existing vectors
**Then** I see a warning: "Dimension mismatch - existing vectors may need re-embedding"

**AC-7.2.4: Model health check**
**Given** I am on the LLM config page
**Then** I see health status for each configured model
**And** last successful request timestamp

**Prerequisites:** Story 5.5 (System Configuration)

**Technical Notes:**
- LiteLLM proxy handles model routing
- Config stored in system_config table
- Existing implementation: backend/app/core/config.py, infrastructure/docker/litellm_config.yaml

---

### Story 7.3: CI/CD Pipeline Setup

**Description:** As a developer, I want automated CI/CD pipelines so code changes are automatically tested and deployable.

**Story Points:** 5

**Acceptance Criteria:**

**AC-7.3.1: Pull request checks**
**Given** I create a pull request
**Then** GitHub Actions runs: lint, type-check, unit tests, build

**AC-7.3.2: Main branch deployment**
**Given** a PR is merged to main
**Then** Docker images are built and pushed to registry
**And** staging environment is updated

**AC-7.3.3: Test coverage reporting**
**Given** CI runs on a PR
**Then** coverage report is posted as PR comment
**And** coverage badge is updated

**AC-7.3.4: Parallel test execution**
**Given** CI runs tests
**Then** frontend and backend tests run in parallel
**And** total CI time is under 10 minutes

**Prerequisites:** Story 7.1 (Docker E2E Infrastructure)

**Technical Notes:**
- GitHub Actions workflow files in .github/workflows/
- Docker Hub or GitHub Container Registry
- Coverage via pytest-cov and vitest coverage

---

### Story 7.4: Production Deployment Configuration

**Description:** As a DevOps engineer, I want production deployment configuration so the application can be deployed to production infrastructure.

**Story Points:** 5

**Acceptance Criteria:**

**AC-7.4.1: Production docker-compose**
**Given** I have a production server
**When** I run docker compose -f docker-compose.prod.yml up
**Then** all services start with production settings

**AC-7.4.2: Kubernetes manifests (optional)**
**Given** I have a K8s cluster
**When** I apply the manifests
**Then** all workloads are deployed with proper resources

**AC-7.4.3: Environment configuration**
**Given** production deployment
**Then** all secrets are loaded from environment/secrets manager
**And** no hardcoded credentials exist

**AC-7.4.4: Health check endpoints**
**Given** production deployment
**Then** /health and /ready endpoints are available
**And** orchestrator can verify service health

**Prerequisites:** None

**Technical Notes:**
- docker-compose.prod.yml with production overrides
- Optional: Kubernetes manifests or Helm charts
- Secret management via environment variables

---

### Story 7.5: Monitoring & Observability

**Description:** As a DevOps engineer, I want monitoring and observability so I can track system health and diagnose issues.

**Story Points:** 5

**Acceptance Criteria:**

**AC-7.5.1: Prometheus metrics endpoint**
**Given** the backend is running
**Then** /metrics endpoint exposes Prometheus metrics
**And** includes request latency, error rates, active connections

**AC-7.5.2: Grafana dashboards**
**Given** Prometheus is scraping metrics
**Then** Grafana dashboards show: API latency, error rates, queue depth, DB connections

**AC-7.5.3: Alerting rules**
**Given** error rate exceeds threshold (5%)
**Then** alert is triggered
**And** notification sent (email/Slack)

**AC-7.5.4: Log aggregation**
**Given** services are running
**Then** logs are aggregated in structured JSON format
**And** queryable via log viewer

**Prerequisites:** Story 7.4 (Production Deployment)

**Technical Notes:**
- prometheus-fastapi-instrumentator for metrics
- Grafana with pre-built dashboards
- AlertManager for notifications

---

### Story 7.6: Backend Unit Test Fixes

**Description:** As a developer, I want all backend unit tests passing so I have confidence in test coverage.

**Story Points:** 3

**Tech Debt Reference:** TD-5.15-1

**Acceptance Criteria:**

**AC-7.6.1: Draft service tests passing**
**Given** I run pytest tests/unit/test_draft_service.py
**Then** all 12 tests pass

**AC-7.6.2: Search service tests passing**
**Given** I run pytest tests/unit/test_search_service.py
**Then** all 8 tests pass

**AC-7.6.3: Generation service tests passing**
**Given** I run pytest tests/unit/test_generation_service.py
**Then** all 5 tests pass

**AC-7.6.4: Explanation service tests passing**
**Given** I run pytest tests/unit/test_explanation_service.py
**Then** all tests pass

**AC-7.6.5: DI pattern documented**
**Given** tests are fixed
**Then** a comment or doc explains the DI mock pattern for future tests

**Prerequisites:** None

**Technical Notes:**
- Root cause: Service constructor DI changes not reflected in test mocks
- Update test fixtures to match current DI patterns

---

### Story 7.7: Async Qdrant Client Migration

**Description:** As a developer, I want async Qdrant client so vector operations don't block the event loop.

**Story Points:** 5

**Tech Debt Reference:** TD-5.26-1

**Acceptance Criteria:**

**AC-7.7.1: AsyncQdrantClient used**
**Given** I inspect backend/app/integrations/qdrant_client.py
**Then** it uses AsyncQdrantClient instead of sync QdrantClient

**AC-7.7.2: ChunkService fully async**
**Given** I inspect chunk_service.py
**Then** all Qdrant calls are native async (no asyncio.to_thread)

**AC-7.7.3: SearchService fully async**
**Given** I inspect search_service.py
**Then** all Qdrant calls are native async

**AC-7.7.4: Load test validates concurrency**
**Given** I run concurrent requests (100 simultaneous)
**Then** response times remain consistent
**And** no event loop blocking observed

**Prerequisites:** None

**Technical Notes:**
- Replace QdrantClient with AsyncQdrantClient
- Update all service methods to use async calls
- Remove asyncio.to_thread workarounds

---

### Story 7.8: UI Scroll Isolation Fix

**Description:** As a user, I want split-pane scroll isolation so scrolling one panel doesn't affect the other.

**Story Points:** 3

**Tech Debt Reference:** TD-scroll-1

**Acceptance Criteria:**

**AC-7.8.1: Document viewer scroll isolated**
**Given** I am viewing the Document Chunk Viewer
**When** I scroll in the document panel
**Then** the chunk list panel does not scroll

**AC-7.8.2: Chunk list scroll isolated**
**Given** I am viewing the Document Chunk Viewer
**When** I scroll in the chunk list panel
**Then** the document panel does not scroll

**AC-7.8.3: Resize maintains isolation**
**Given** I resize the split panes
**Then** scroll isolation is maintained

**Prerequisites:** Story 5.26 (Document Chunk Viewer Frontend)

**Technical Notes:**
- Multiple solutions attempted without success
- May require CSS overflow:hidden + custom scroll containers
- Test with various document sizes

---

### Story 7.9: LLM Model Registry

**Description:** As an admin, I want to register and manage LLM models so users can select appropriate models for their Knowledge Bases.

**Story Points:** 8

**Acceptance Criteria:**

**AC-7.9.1: Model registration page**
**Given** I am logged in as admin
**When** I navigate to Admin > Model Registry
**Then** I see a list of registered models with their configurations

**AC-7.9.2: Register new model**
**Given** I am on Model Registry
**When** I click "Add Model"
**Then** I see a form with fields based on model type

**AC-7.9.3: Model type selection**
**Given** I am registering a new model
**When** I select model type
**Then** I can choose: "Embedding" or "Generation"

**AC-7.9.4: Provider selection with dynamic fields**
**Given** I am registering a model
**When** I select provider
**Then** appropriate fields are shown:

| Provider | Required Fields |
|----------|-----------------|
| Ollama (Local) | Base URL, Model Name |
| OpenAI | API Key, Model Name, Organization ID (optional) |
| Google Gemini | API Key, Model Name, Project ID (optional) |
| Azure OpenAI | API Key, Endpoint URL, Deployment Name, API Version |
| Anthropic | API Key, Model Name |
| Cohere | API Key, Model Name |
| Custom/OpenAI-compatible | Base URL, API Key (optional), Model Name |

**AC-7.9.5: Embedding model parameters**
**Given** I am registering an Embedding model
**Then** I must provide:

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `name` | string | Display name | "Nomic Embed Text" |
| `provider` | enum | Provider type | ollama, openai, cohere |
| `model_id` | string | Model identifier | "nomic-embed-text" |
| `dimensions` | int | Vector dimensions | 768, 1536, 3072 |
| `max_tokens` | int | Max input tokens | 8192 |
| `normalize` | bool | Normalize vectors | true |
| `distance_metric` | enum | Similarity metric | cosine, dot, euclidean |
| `batch_size` | int | Batch size for bulk embedding | 32 |
| `tags` | string[] | Searchable tags | ["local", "fast", "multilingual"] |

**AC-7.9.6: Generation model parameters**
**Given** I am registering a Generation model
**Then** I must provide:

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `name` | string | Display name | "GPT-4o" |
| `provider` | enum | Provider type | openai, anthropic, ollama |
| `model_id` | string | Model identifier | "gpt-4o" |
| `context_window` | int | Max context tokens | 128000 |
| `max_output_tokens` | int | Max response tokens | 16384 |
| `supports_streaming` | bool | SSE streaming support | true |
| `supports_json_mode` | bool | Structured output | true |
| `supports_vision` | bool | Image input support | true |
| `temperature_default` | float | Default temperature | 0.7 |
| `temperature_range` | [float, float] | Valid range | [0.0, 2.0] |
| `top_p_default` | float | Default nucleus sampling | 1.0 |
| `top_k_default` | int | Default top-k (if supported) | 40 |
| `frequency_penalty_default` | float | Repetition penalty | 0.0 |
| `presence_penalty_default` | float | Topic novelty penalty | 0.0 |
| `cost_per_1k_input` | float | Cost tracking (USD) | 0.0025 |
| `cost_per_1k_output` | float | Cost tracking (USD) | 0.01 |
| `tags` | string[] | Searchable tags | ["cloud", "fast", "reasoning"] |

**AC-7.9.7: RAG/Search parameters (shared)**
**Given** I am configuring search defaults for a model
**Then** I can set:

| Parameter | Type | Description | Example |
|-----------|------|-------------|---------|
| `similarity_threshold` | float | Min similarity score | 0.7 |
| `top_k` | int | Number of chunks to retrieve | 10 |
| `rerank_enabled` | bool | Enable reranking | true |
| `rerank_model` | string | Rerank model (if enabled) | "cohere-rerank-v3" |
| `hybrid_search` | bool | Combine vector + keyword | false |
| `mmr_enabled` | bool | Maximal Marginal Relevance | true |
| `mmr_lambda` | float | MMR diversity factor | 0.5 |

**AC-7.9.8: Connection test**
**Given** I have filled in model configuration
**When** I click "Test Connection"
**Then** system validates connectivity and returns:
- For embedding: sample text embedded, dimensions verified
- For generation: simple prompt completed, streaming verified

**AC-7.9.9: Model status management**
**Given** a model is registered
**Then** I can set status: Active, Inactive, Deprecated
**And** only Active models appear in KB configuration

**AC-7.9.10: Default model designation**
**Given** I have multiple models of same type
**When** I mark one as "System Default"
**Then** new KBs use this model unless overridden

**AC-7.9.11: Model edit and delete**
**Given** a model is registered
**When** I edit or delete it
**Then** I see warning if any KBs are using this model
**And** deletion is blocked if KBs depend on it

**AC-7.9.12: Audit logging**
**Given** any model registry change occurs
**Then** audit log captures: action, user, timestamp, old/new values

**Prerequisites:** Story 5.5 (System Configuration)

**Technical Notes:**
- New table: `llm_models` (id, type, provider, name, config JSONB, status, is_default, created_at, updated_at)
- LiteLLM proxy integration for unified API
- Secure storage for API keys (encrypted at rest)
- Migration to add model registry schema

---

### Story 7.10: KB Model Configuration

**Description:** As a KB creator, I want to select embedding and generation models for my Knowledge Base so documents are processed with appropriate models.

**Story Points:** 5

**Acceptance Criteria:**

**AC-7.10.1: Model selection during KB creation**
**Given** I am creating a new Knowledge Base
**When** I fill in the creation form
**Then** I see model selection section with:
- Embedding Model dropdown (required)
- Generation Model dropdown (required)

**AC-7.10.2: Only active models shown**
**Given** I am selecting models for a KB
**Then** only models with status "Active" appear in dropdowns
**And** system default is pre-selected

**AC-7.10.3: Model info display**
**Given** I select a model
**Then** I see key parameters:
- For embedding: dimensions, provider, tags
- For generation: context window, provider, streaming support

**AC-7.10.4: Qdrant collection auto-creation**
**Given** I create a KB with embedding model
**When** KB is created
**Then** Qdrant collection is created with:
- Collection name: `kb_{kb_id}`
- Vector size: from embedding model dimensions
- Distance metric: from embedding model config (cosine/dot/euclidean)
- Optimizers config based on expected document count

**AC-7.10.5: KB-level parameter overrides**
**Given** I am configuring a KB
**Then** I can override default search parameters:

| Parameter | Description | Inherits From |
|-----------|-------------|---------------|
| `similarity_threshold` | Min relevance score | Model default |
| `top_k` | Chunks to retrieve | Model default |
| `chunk_size` | Document chunk size | System default (512) |
| `chunk_overlap` | Overlap between chunks | System default (50) |
| `temperature` | Generation temperature | Model default |
| `max_response_tokens` | Max generation length | Model default |

**AC-7.10.6: Model lock after first document**
**Given** a KB has documents uploaded
**When** I try to change the embedding model
**Then** I see warning: "Changing embedding model requires re-processing all documents"
**And** I must confirm to proceed

**AC-7.10.7: Generation model changeable**
**Given** a KB exists with documents
**When** I change the generation model
**Then** change applies immediately (no reprocessing needed)

**AC-7.10.8: KB settings page shows model info**
**Given** I view KB settings
**Then** I see current model assignments
**And** link to model details in admin registry

**AC-7.10.9: Document processing uses KB models**
**Given** a document is uploaded to a KB
**When** processing starts
**Then** embedding uses KB's configured embedding model
**And** vectors are stored with correct dimensions

**AC-7.10.10: Search/chat uses KB models**
**Given** I search or chat in a KB
**Then** retrieval uses KB's embedding model
**And** generation uses KB's generation model
**And** parameters respect KB-level overrides

**Prerequisites:**
- Story 7.9 (LLM Model Registry)
- Story 2.1 (Knowledge Base CRUD)

**Technical Notes:**
- Add to `knowledge_bases` table: `embedding_model_id`, `generation_model_id`, `config_overrides JSONB`
- Qdrant collection creation: `qdrant_client.create_collection(name, vectors_config)`
- Update document processing worker to read KB model config
- Update search/chat services to use KB-specific models

---

### Story 7.11: Navigation Restructure with RBAC Default Groups

**Description:** As an administrator, I want a restructured navigation with separate Operations and Admin menus, and three default user groups (Users, Operators, Administrators) with cumulative permissions, so that users see appropriate UI elements based on their role, and permission management is simplified through a clear hierarchical group system.

**Story Points:** 8

**Acceptance Criteria:**

**Navigation Restructure:**

**AC-7.11.1: Admin sees dual menus**
**Given** an Administrator views the application header
**Then** they see two dropdown menus: "Operations" and "Admin"

**AC-7.11.2: Operator sees Operations only**
**Given** an Operator user views the header
**Then** they see only the "Operations" dropdown (no "Admin" menu)

**AC-7.11.3: Basic User sees neither menu**
**Given** a basic User views the header
**Then** they see neither Operations nor Admin menus (only Search)

**AC-7.11.4: Operations menu items**
**Given** the Operations dropdown is opened
**Then** it displays: Operations Dashboard (hub), Audit Logs, Processing Queue, KB Statistics

**AC-7.11.5: Admin menu items**
**Given** the Admin dropdown is opened
**Then** it displays: Admin Dashboard (hub), Users, Groups, KB Permissions, System Config, Model Registry

**AC-7.11.6: Hub dashboards**
**Given** clicking "Operations Dashboard" or "Admin Dashboard"
**When** the page loads
**Then** it shows a card-based hub with links to all sub-sections

**Default Groups:**

**AC-7.11.7: System groups seeded**
**Given** a fresh installation
**When** the database is seeded
**Then** three system groups exist: "Users" (level 1), "Operators" (level 2), "Administrators" (level 3)

**AC-7.11.8: System groups protected**
**Given** system default groups
**When** an admin attempts to delete them
**Then** the operation is blocked with error "Cannot delete system groups"

**AC-7.11.9: System group membership editable**
**Given** system default groups
**When** an admin edits membership
**Then** members can be added/removed normally

**AC-7.11.10: Auto-assign new users**
**Given** a new user registration
**When** the account is created
**Then** the user is automatically added to the "Users" group

**Permission Hierarchy (Cumulative):**

**AC-7.11.11: Cumulative permissions**
**Given** permission levels (User=1, Operator=2, Admin=3)
**When** checking permissions
**Then** higher levels inherit all lower-level permissions

**AC-7.11.12: User upload restriction**
**Given** a User (level 1)
**When** they try to upload documents
**Then** the upload button is hidden and API returns 403

**AC-7.11.13: Operator capabilities**
**Given** an Operator (level 2)
**When** they access the application
**Then** they can upload/delete documents, create KBs, and view Operations menu

**AC-7.11.14: Operator KB deletion restriction**
**Given** an Operator (level 2)
**When** they try to delete a Knowledge Base
**Then** the operation is blocked (Admin only)

**AC-7.11.15: Administrator full access**
**Given** an Administrator (level 3)
**When** they access the application
**Then** they have full access including KB deletion and Admin menu

**Route Protection:**

**AC-7.11.16: User route block**
**Given** a User accessing `/operations/*` routes
**When** the page loads
**Then** they are redirected with 403 Forbidden

**AC-7.11.17: Operator admin route block**
**Given** an Operator accessing `/admin/*` routes
**When** the page loads
**Then** they are redirected with 403 Forbidden

**AC-7.11.18: Admin unrestricted access**
**Given** an Administrator
**When** accessing any route
**Then** access is granted

**Safety Guards:**

**AC-7.11.19: Last admin protection**
**Given** the last Administrator in the system
**When** attempting to remove themselves from Administrators group
**Then** the operation is blocked with error "Cannot remove the last administrator"

**AC-7.11.20: Max permission level**
**Given** a user in multiple groups
**When** checking their permission level
**Then** the MAX permission_level across all groups is used

**Prerequisites:**
- Story 5.17 (Main Navigation) - navigation structure to extend
- Story 5.19 (Group Management) - group CRUD to extend
- Story 7.9 (LLM Model Registry) - admin route pattern reference

**Technical Notes:**
- Add `permission_level` (integer 1-3) and `is_system` (boolean) columns to groups table
- Create `PermissionService` with `get_user_permission_level(user)` method
- Create `@require_permission(level)` decorator for endpoints
- Cumulative permission check: `user_max_level >= required_level`
- Frontend: `OperationsDropdown`, `AdminDropdown` components, `usePermissionLevel()` hook
- Route guards: `OperatorGuard`, `AdminGuard` HOCs
- Auto-add new users to "Users" group in registration flow

---

## Epic 8: GraphRAG Integration

**Goal:** Enhance chat response quality through domain-driven knowledge graphs with per-KB schemas for context-aware entity relationships.

**User Value:** Users receive more accurate, contextually-aware answers that understand entity relationships across documents. Each Knowledge Base can define its own domain-specific entity types and relationships, enabling tailored knowledge graphs for IT Operations, Legal, Sales, Project Management, and other domains.

**FRs Covered:** FR78-FR92 (new FRs for GraphRAG capabilities)

**Technical Foundation:**
- Neo4j Community Edition for graph storage
- LLM-based entity extraction via LiteLLM (NER model type)
- Per-KB domain schemas with reusable domain definitions
- Vector-first + Graph-augment retrieval strategy
- Designed for future Parallel Merge upgrade path

**Key Architectural Decisions:**
- **Graph Database:** Neo4j Community Edition - proven, great Python driver, Docker-ready
- **Entity Extraction:** LLM-based via existing LiteLLM proxy with new NER model type
- **Retrieval Strategy:** Vector-first + Graph-augment (Phase 1), designed for Parallel Merge (Phase 2)
- **Schema Model:** Per-KB domain schemas with reusable domain definitions across KBs

---

### Story 8.1: Neo4j Docker Infrastructure

**Description:** As a developer, I want Neo4j added to the Docker infrastructure so GraphRAG can store and query knowledge graphs.

**Story Points:** 2

**Acceptance Criteria:**

**AC-8.1.1: Neo4j in docker-compose**
**Given** I run docker-compose up
**Then** Neo4j Community Edition starts alongside other services
**And** exposes Bolt port (7687) and HTTP port (7474)

**AC-8.1.2: Health check endpoint**
**Given** Neo4j is running
**Then** /health endpoint returns healthy status
**And** orchestrator can verify graph database availability

**AC-8.1.3: Connection pooling**
**Given** backend connects to Neo4j
**Then** connection pool is configured (min: 5, max: 50)
**And** connections are reused efficiently

**AC-8.1.4: Persistent storage**
**Given** docker-compose is restarted
**Then** Neo4j data persists via mounted volume
**And** no graph data is lost

**AC-8.1.5: Environment configuration**
**Given** deployment environment
**Then** Neo4j credentials are configurable via environment variables
**And** no hardcoded credentials exist

**Prerequisites:** None

**Technical Notes:**
- Add neo4j service to infrastructure/docker/docker-compose.yml
- Create backend/app/integrations/neo4j_client.py
- Add NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD to config

---

### Story 8.2: Domain Data Model & Migrations

**Description:** As a developer, I want database tables for domain definitions so entity types and relationships can be stored and managed.

**Story Points:** 3

**Acceptance Criteria:**

**AC-8.2.1: Domains table created**
**Given** I run alembic upgrade
**Then** `domains` table exists with columns: id, name, description, is_system_template, is_public, created_by, created_at, updated_at

**AC-8.2.2: Entity types table created**
**Given** I run alembic upgrade
**Then** `domain_entity_types` table exists with columns: id, domain_id, name, description, attributes (JSONB), color, icon, extraction_hints, sort_order

**AC-8.2.3: Relationship types table created**
**Given** I run alembic upgrade
**Then** `domain_relationship_types` table exists with columns: id, domain_id, name, description, from_entity_type_id, to_entity_type_id, attributes (JSONB), bidirectional, extraction_hints

**AC-8.2.4: Domain versions table created**
**Given** I run alembic upgrade
**Then** `domain_versions` table exists for schema version history

**AC-8.2.5: KB-Domain link**
**Given** I run alembic upgrade
**Then** `knowledge_bases` table has `domain_id` foreign key column

**AC-8.2.6: Document graph status**
**Given** I run alembic upgrade
**Then** `documents` table has `graph_extraction_status`, `graph_extracted_at`, `graph_schema_version` columns

**Prerequisites:** None

**Technical Notes:**
- Alembic migration for all new tables
- SQLAlchemy models in backend/app/models/domain.py
- Pydantic schemas in backend/app/schemas/domain.py

---

### Story 8.3: System Domain Templates

**Description:** As an admin, I want pre-built domain templates so users can quickly start with common domain schemas.

**Story Points:** 3

**Acceptance Criteria:**

**AC-8.3.1: IT Operations template**
**Given** I view domain templates
**Then** I see "IT Operations" with entities: Server, Application, Incident, Team, Service, Database, SLA
**And** relationships: hosts, depends_on, assigned_to, connects_to, affects, has_sla

**AC-8.3.2: Legal/Contracts template**
**Given** I view domain templates
**Then** I see "Legal" with entities: Contract, Party, Clause, Obligation, Jurisdiction, Date
**And** relationships: binds, references, amends, governs, signed_by, expires_on

**AC-8.3.3: Sales & Marketing template**
**Given** I view domain templates
**Then** I see "Sales & Marketing" with entities: Campaign, Lead, Account, Product, Competitor, Channel
**And** relationships: targets, converts, competes_with, influences, runs_on

**AC-8.3.4: Project Management template**
**Given** I view domain templates
**Then** I see "Project Management" with entities: Project, Task, Milestone, Resource, Risk, Deliverable
**And** relationships: contains, blocks, assigned_to, mitigates, delivers, depends_on

**AC-8.3.5: HR/People template**
**Given** I view domain templates
**Then** I see "HR/People" with entities: Employee, Department, Role, Skill, Policy, Training
**And** relationships: reports_to, has_skill, member_of, governs, completed

**AC-8.3.6: Templates marked as system**
**Given** templates are loaded
**Then** all templates have is_system_template=true
**And** cannot be deleted by users

**Prerequisites:** Story 8.2 (Domain Data Model)

**Technical Notes:**
- Seed data in backend/app/seeds/domain_templates.py
- Load via alembic data migration or startup script
- Each template includes extraction_hints for LLM guidance

---

### Story 8.4: LLM Domain Recommendation Service

**Description:** As a user, I want LLM-powered domain schema recommendations so I can quickly define appropriate entities and relationships for my KB.

**Story Points:** 5

**Acceptance Criteria:**

**AC-8.4.1: Recommendation from description**
**Given** I provide a domain name and description
**When** I request LLM recommendations
**Then** I receive suggested entity types with descriptions
**And** suggested relationship types with from/to entity mappings

**AC-8.4.2: Uses NER model from registry**
**Given** NER model is configured in model registry
**When** recommendation is requested
**Then** the configured NER model is used via LiteLLM

**AC-8.4.3: Structured output**
**Given** LLM generates recommendations
**Then** output is parsed into valid EntityType and RelationshipType schemas
**And** includes extraction_hints for each type

**AC-8.4.4: Template matching**
**Given** description matches a known domain (e.g., "IT infrastructure")
**When** recommendations are generated
**Then** system suggests starting from matching template
**And** provides additional custom recommendations

**AC-8.4.5: Confidence scores**
**Given** recommendations are generated
**Then** each entity/relationship includes confidence score (0-1)
**And** user can filter by minimum confidence

**Prerequisites:** Story 7.9 (LLM Model Registry with NER type)

**Technical Notes:**
- backend/app/services/domain_recommendation_service.py
- Prompt engineering for structured entity/relationship extraction
- JSON mode output for reliable parsing

---

### Story 8.5: Domain Management API

**Description:** As a developer, I want CRUD API endpoints for domains so the frontend can manage domain definitions.

**Story Points:** 5

**Acceptance Criteria:**

**AC-8.5.1: List domains**
**Given** I call GET /api/v1/domains
**Then** I receive list of domains with entity/relationship counts
**And** can filter by is_system_template, is_public

**AC-8.5.2: Get domain details**
**Given** I call GET /api/v1/domains/{id}
**Then** I receive full domain with all entity types and relationship types

**AC-8.5.3: Create domain**
**Given** I call POST /api/v1/domains with name, description, entity_types, relationship_types
**Then** domain is created and returned with ID

**AC-8.5.4: Update domain**
**Given** I call PUT /api/v1/domains/{id}
**Then** domain is updated
**And** version history entry is created

**AC-8.5.5: Delete domain**
**Given** I call DELETE /api/v1/domains/{id}
**When** no KBs are using this domain
**Then** domain is deleted

**AC-8.5.6: Clone domain**
**Given** I call POST /api/v1/domains/{id}/clone
**Then** new domain is created with copied schema
**And** is_system_template is set to false

**AC-8.5.7: Get recommendations**
**Given** I call POST /api/v1/domains/recommend with name, description
**Then** I receive LLM-generated entity and relationship suggestions

**AC-8.5.8: Entity type CRUD**
**Given** I call POST/PUT/DELETE /api/v1/domains/{id}/entity-types
**Then** entity types are managed within domain

**AC-8.5.9: Relationship type CRUD**
**Given** I call POST/PUT/DELETE /api/v1/domains/{id}/relationship-types
**Then** relationship types are managed within domain

**Prerequisites:** Story 8.2, 8.4

**Technical Notes:**
- backend/app/api/v1/domains.py
- backend/app/services/domain_service.py
- Permission: Admin can manage all, users can manage own domains

---

### Story 8.6: Domain Management UI

**Description:** As an admin, I want a UI for creating and editing domains so I can define entity types and relationships visually.

**Story Points:** 8

**Acceptance Criteria:**

**AC-8.6.1: Domain list page**
**Given** I navigate to Admin > Domains
**Then** I see list of all domains with name, entity count, relationship count, KB usage count

**AC-8.6.2: Create domain form**
**Given** I click "Create Domain"
**Then** I see form with name, description fields
**And** "Get LLM Recommendations" button

**AC-8.6.3: LLM recommendation integration**
**Given** I click "Get LLM Recommendations"
**Then** loading indicator shows
**And** suggested entities and relationships populate the form

**AC-8.6.4: Entity type editor**
**Given** I am editing a domain
**Then** I can add/edit/delete entity types
**And** configure: name, description, color, icon, attributes, extraction_hints

**AC-8.6.5: Relationship type editor**
**Given** I am editing a domain
**Then** I can add/edit/delete relationship types
**And** configure: name, from_type, to_type, description, bidirectional, extraction_hints

**AC-8.6.6: Visual relationship diagram**
**Given** I am viewing a domain
**Then** I see visual diagram showing entities as nodes and relationships as edges

**AC-8.6.7: Template selection**
**Given** I am creating a domain
**Then** I can start from a system template
**And** template schema is copied to new domain

**AC-8.6.8: Validation**
**Given** I save a domain
**Then** validation ensures: unique entity names, valid relationship references, no orphan types

**AC-8.6.9: Delete protection**
**Given** a domain is used by KBs
**When** I try to delete it
**Then** I see warning with list of dependent KBs
**And** deletion is blocked

**Prerequisites:** Story 8.5

**Technical Notes:**
- frontend/src/app/(protected)/admin/domains/page.tsx
- frontend/src/components/admin/domain-editor.tsx
- Use react-flow or similar for visual diagram

---

### Story 8.7: KB-Domain Linking

**Description:** As a KB creator, I want to associate my Knowledge Base with a domain so documents are extracted using the appropriate schema.

**Story Points:** 3

**Acceptance Criteria:**

**AC-8.7.1: Domain selection in KB creation**
**Given** I am creating a new Knowledge Base
**Then** I see domain selection dropdown with options:
- System templates
- My domains
- Public domains
- "Create New Domain..."
- "No Domain (skip GraphRAG)"

**AC-8.7.2: Domain preview**
**Given** I select a domain
**Then** I see preview of entity types and relationship types

**AC-8.7.3: Create domain inline**
**Given** I select "Create New Domain..."
**Then** domain creation modal opens
**And** new domain is linked after creation

**AC-8.7.4: KB settings shows domain**
**Given** I view KB settings
**Then** I see linked domain with link to domain details

**AC-8.7.5: Change domain warning**
**Given** KB has documents with graph extractions
**When** I try to change domain
**Then** I see warning: "Changing domain requires re-extraction of all documents"
**And** I must confirm to proceed

**AC-8.7.6: No domain option**
**Given** I select "No Domain"
**Then** KB is created without GraphRAG capabilities
**And** documents are processed with vector-only (existing behavior)

**Prerequisites:** Story 8.6

**Technical Notes:**
- Update frontend/src/components/kb/kb-create-modal.tsx
- Add domain_id to KB creation/update API calls

---

### Story 8.8: Per-KB Entity Extraction Service

**Description:** As a system, I want to extract entities from documents using the KB's domain schema so knowledge graphs are domain-specific.

**Story Points:** 5

**Acceptance Criteria:**

**AC-8.8.1: Load KB domain schema**
**Given** a document is being processed
**When** entity extraction starts
**Then** KB's linked domain schema is loaded

**AC-8.8.2: Schema-aware extraction prompt**
**Given** domain schema is loaded
**Then** LLM prompt includes:
- List of valid entity types with descriptions
- List of valid relationship types with from/to constraints
- Extraction hints from schema

**AC-8.8.3: Extract entities from chunks**
**Given** document chunks are available
**When** extraction runs
**Then** entities are extracted with: type, name, attributes, source_chunk_id

**AC-8.8.4: Extract relationships**
**Given** entities are extracted
**When** relationship extraction runs
**Then** relationships are extracted with: type, from_entity, to_entity, attributes

**AC-8.8.5: Handle unknown entities**
**Given** LLM finds entity not matching schema
**Then** entity is tagged as "unmatched" for later review
**And** suggested type is recorded

**AC-8.8.6: Batch processing**
**Given** large document with many chunks
**Then** extraction is batched (configurable batch_size)
**And** progress is tracked

**AC-8.8.7: Extraction metrics**
**Given** extraction completes
**Then** metrics are recorded: entities_found, relationships_found, unmatched_count, processing_time

**Prerequisites:** Story 8.4, 8.7

**Technical Notes:**
- backend/app/services/entity_extraction_service.py
- Prompt template in backend/app/prompts/entity_extraction.py
- Uses NER model from model registry

---

### Story 8.9: Document Processing Graph Integration

**Description:** As a system, I want entity extraction integrated into the document processing pipeline so graphs are built during ingestion.

**Story Points:** 5

**Acceptance Criteria:**

**AC-8.9.1: Graph extraction step added**
**Given** document processing pipeline
**Then** new step "graph_extraction" follows embedding step

**AC-8.9.2: Skip if no domain**
**Given** KB has no linked domain
**When** document is processed
**Then** graph extraction step is skipped
**And** status shows "skipped - no domain"

**AC-8.9.3: Store entities in Neo4j**
**Given** entities are extracted
**Then** nodes are created in Neo4j with:
- Label: `Entity_{kb_id}`
- Properties: type, name, attributes, document_id, chunk_id

**AC-8.9.4: Store relationships in Neo4j**
**Given** relationships are extracted
**Then** edges are created in Neo4j with:
- Type: relationship_name
- Properties: attributes, document_id, confidence

**AC-8.9.5: Update document status**
**Given** graph extraction completes
**Then** document.graph_extraction_status = "completed"
**And** document.graph_extracted_at = now()
**And** document.graph_schema_version = domain.version

**AC-8.9.6: Handle extraction failure**
**Given** graph extraction fails
**Then** document.graph_extraction_status = "failed"
**And** error is logged
**And** document processing continues (vector search still works)

**AC-8.9.7: Processing status includes graph**
**Given** I view document processing status
**Then** I see graph extraction step with status

**Prerequisites:** Story 8.1, 8.8

**Technical Notes:**
- Update backend/app/workers/document_tasks.py
- Add graph extraction to Celery task chain
- Graceful degradation on graph failure

---

### Story 8.10: Graph Query Service

**Description:** As a developer, I want a service for querying the knowledge graph so retrieval can traverse entity relationships.

**Story Points:** 3

**Acceptance Criteria:**

**AC-8.10.1: Find entities by name**
**Given** I query for entity by name/partial match
**Then** matching entities are returned with type and attributes

**AC-8.10.2: Traverse relationships**
**Given** I have an entity
**When** I request traversal with max_hops
**Then** related entities are returned up to max_hops distance

**AC-8.10.3: Filter by relationship type**
**Given** I traverse from an entity
**Then** I can filter by specific relationship types

**AC-8.10.4: Get entity's chunks**
**Given** I have an entity
**Then** I can retrieve source chunk IDs for that entity

**AC-8.10.5: KB-scoped queries**
**Given** I query the graph
**Then** results are scoped to the specified KB's entities

**AC-8.10.6: Query performance**
**Given** graph with 100k entities
**Then** traversal queries return in < 100ms

**Prerequisites:** Story 8.9

**Technical Notes:**
- backend/app/services/graph_query_service.py
- Cypher queries for Neo4j
- Index entities by name and type for fast lookup

---

### Story 8.11: Graph-Augmented Retrieval

**Description:** As a user, I want my search results enhanced with graph context so related entities are included in the response.

**Story Points:** 5

**Acceptance Criteria:**

**AC-8.11.1: Vector search first**
**Given** user submits a query
**Then** standard vector search returns top-K chunks

**AC-8.11.2: Extract entities from results**
**Given** vector results are available
**Then** entities mentioned in top chunks are identified

**AC-8.11.3: Graph traversal**
**Given** entities are identified
**Then** graph is traversed (1-2 hops) to find related entities

**AC-8.11.4: Fetch related chunks**
**Given** related entities are found
**Then** chunks containing those entities are retrieved

**AC-8.11.5: Merge and dedupe**
**Given** vector chunks and graph chunks are available
**Then** results are merged with duplicates removed

**AC-8.11.6: Rerank combined results**
**Given** merged results
**Then** results are reranked by relevance to original query
**And** final top-K returned to LLM

**AC-8.11.7: Graceful degradation**
**Given** graph query fails
**Then** vector results are returned without graph augmentation
**And** warning is logged

**AC-8.11.8: Performance target**
**Given** query with graph augmentation
**Then** total retrieval time < 200ms additional latency

**Prerequisites:** Story 8.10

**Technical Notes:**
- Update backend/app/services/search_service.py
- Add graph_augmentation optional parameter
- Enabled by default for KBs with domains

---

### Story 8.12: Retrieval Strategy Abstraction

**Description:** As a developer, I want a retrieval strategy abstraction so future retrieval methods (Parallel Merge) can be added easily.

**Story Points:** 3

**Acceptance Criteria:**

**AC-8.12.1: Strategy interface**
**Given** I implement a new retrieval strategy
**Then** I extend RetrievalStrategy base class with retrieve() method

**AC-8.12.2: Vector-only strategy**
**Given** KB has no domain
**Then** VectorOnlyStrategy is used

**AC-8.12.3: Graph-augment strategy**
**Given** KB has domain
**Then** GraphAugmentStrategy is used by default

**AC-8.12.4: Strategy selection**
**Given** retrieval is requested
**Then** appropriate strategy is selected based on KB configuration

**AC-8.12.5: Feature flag ready**
**Given** new strategy is implemented
**Then** feature flag can switch between strategies

**AC-8.12.6: Strategy metrics**
**Given** retrieval completes
**Then** metrics include strategy used and timing breakdown

**Prerequisites:** Story 8.11

**Technical Notes:**
- backend/app/services/retrieval/base.py - RetrievalStrategy ABC
- backend/app/services/retrieval/vector_only.py
- backend/app/services/retrieval/graph_augment.py
- Factory pattern for strategy selection

---

### Story 8.13: LLM Schema Enrichment Suggestions

**Description:** As an admin, I want LLM-suggested schema enrichments so domains can evolve based on document content.

**Story Points:** 5

**Acceptance Criteria:**

**AC-8.13.1: Track unmatched entities**
**Given** entity extraction finds entities not matching schema
**Then** unmatched entities are stored with suggested type and frequency

**AC-8.13.2: Aggregate suggestions**
**Given** multiple documents have unmatched entities
**Then** suggestions are aggregated by suggested type with total counts

**AC-8.13.3: Suggestion notification**
**Given** unmatched entity count exceeds threshold (e.g., 10)
**Then** admin notification is triggered
**And** badge appears on domain in UI

**AC-8.13.4: Review suggestions UI**
**Given** I view domain with suggestions
**Then** I see list of suggested new entity types with:
- Suggested name
- Example values found
- Document count
- Accept/Reject buttons

**AC-8.13.5: Accept suggestion**
**Given** I accept a suggested entity type
**Then** new entity type is added to domain
**And** unmatched entities are reclassified

**AC-8.13.6: Relationship suggestions**
**Given** new entity types are accepted
**Then** LLM suggests potential relationships to existing types

**AC-8.13.7: Suggestion threshold config**
**Given** I configure domain
**Then** I can set minimum frequency for suggestions

**Prerequisites:** Story 8.8, 8.6

**Technical Notes:**
- Store unmatched entities in separate table
- Batch LLM analysis for relationship suggestions
- frontend/src/components/admin/schema-suggestions.tsx

---

### Story 8.14: Schema Evolution & Re-extraction

**Description:** As an admin, I want to trigger re-extraction when domain schema changes so existing documents reflect the updated schema.

**Story Points:** 5

**Acceptance Criteria:**

**AC-8.14.1: Schema version tracking**
**Given** domain is updated
**Then** version is incremented
**And** snapshot is saved to domain_versions table

**AC-8.14.2: Detect outdated documents**
**Given** domain version changes
**Then** documents with older graph_schema_version are identified

**AC-8.14.3: Re-extraction prompt**
**Given** domain is updated
**Then** admin sees prompt: "X documents need re-extraction. Trigger now?"

**AC-8.14.4: Selective re-extraction**
**Given** I trigger re-extraction
**Then** I can choose: all documents, specific documents, or schedule for later

**AC-8.14.5: Queue re-extraction jobs**
**Given** re-extraction is triggered
**Then** jobs are queued with lower priority than new uploads

**AC-8.14.6: Progress tracking**
**Given** re-extraction is running
**Then** I see progress: X of Y documents completed

**AC-8.14.7: Rollback capability**
**Given** re-extraction causes issues
**Then** I can rollback to previous schema version
**And** trigger re-extraction with old schema

**Prerequisites:** Story 8.9, 8.6

**Technical Notes:**
- Re-extraction clears existing graph nodes for document before re-processing
- Use Celery task with rate limiting
- Track re-extraction jobs in documents table

---

### Story 8.15: Batch Re-processing Worker

**Description:** As an admin, I want a batch worker for re-processing existing documents so GraphRAG can be enabled for legacy KBs.

**Story Points:** 3

**Acceptance Criteria:**

**AC-8.15.1: Trigger batch processing**
**Given** I enable GraphRAG on existing KB (add domain)
**Then** I can trigger batch re-processing for all documents

**AC-8.15.2: Queue management**
**Given** batch processing starts
**Then** documents are queued in chunks (e.g., 50 at a time)
**And** rate limiting prevents system overload

**AC-8.15.3: Progress API**
**Given** batch processing is running
**Then** API returns: total, completed, failed, remaining

**AC-8.15.4: Error handling**
**Given** individual document fails
**Then** error is logged
**And** processing continues with next document
**And** failed documents can be retried

**AC-8.15.5: Cancel batch**
**Given** batch processing is running
**Then** I can cancel remaining jobs
**And** completed work is preserved

**AC-8.15.6: Batch completion notification**
**Given** batch processing completes
**Then** admin is notified with summary: completed, failed, time elapsed

**Prerequisites:** Story 8.9

**Technical Notes:**
- backend/app/workers/graph_batch_tasks.py
- Celery chord for parallel processing with callback
- Admin UI shows batch status on KB settings page

---

### Story 8.16: E2E Test Automation

**Description:** As a developer, I want E2E test automation on top of Docker infrastructure so tests can run in CI/CD and validate all epics.

**Story Points:** 5

**Split From:** Story 7.1 (Docker E2E Testing Infrastructure)

**Acceptance Criteria:**
(See specification at docs/sprint-artifacts/8-16-e2e-test-automation.md)

**Prerequisites:** Story 7.1 (Docker E2E Infrastructure), Stories 8.1-8.15 (GraphRAG features to test)

**Technical Notes:**
- Playwright Docker configuration (playwright.config.e2e.ts)
- Dockerfile.playwright for test runner container
- GitHub Actions E2E workflow (.github/workflows/e2e-tests.yml)
- 70+ E2E tests covering Epic 3-8 features
- Test artifacts uploaded on CI runs

---

## FR Coverage Matrix (Updated for Epic 8)

| FR | Epic | Story | Status |
|----|------|-------|--------|
| FR1 | 1 | 1.4 | Covered |
| FR2 | 1 | 1.4 | Covered |
| FR3 | 1 | 1.5 | Covered |
| FR4 | 1 | 1.5 | Covered |
| FR5 | 1, 5 | 1.6, 5.18 | Covered |
| FR6 | 2, 5 | 2.2, 5.19, 5.20 | Covered |
| FR7 | 2, 5 | 2.2, 5.20 | Covered |
| FR8 | 1 | 1.4 | Covered |
| FR8a | 5 | 5.7 | Covered |
| FR8b | 5 | 5.7 | Covered |
| FR8c | 1 | 1.10 | Covered |
| FR9 | 2 | 2.1 | Covered |
| FR10 | 2 | 2.1 | Covered |
| FR10a | 2 | 2.1 | Covered |
| FR11 | 2 | 2.1 | Covered |
| FR12 | 2 | 2.3 | Covered |
| FR12a | 2 | 2.3 | Covered |
| FR12b | 5 | 5.6 | Covered |
| FR12c | 5 | 5.8 | Covered |
| FR12d | 5 | 5.9 | Covered |
| FR13 | 2 | 2.3 | Covered |
| FR14 | 2 | 2.1 | Covered |
| FR15 | 2 | 2.4 | Covered |
| FR16 | 2 | 2.4 | Covered |
| FR17 | 2 | 2.5, 2.6 | Covered |
| FR18 | 2 | 2.7 | Covered |
| FR19 | 2 | 2.7 | Covered |
| FR20 | 2 | 2.8 | Covered |
| FR21 | 2 | 2.8 | Covered |
| FR22 | 2 | 2.10 | Covered |
| FR23 | 2 | 2.10 | Covered |
| FR23a | 2 | 2.12 | Covered |
| FR23b | 2 | 2.12 | Covered |
| FR23c | 2 | 2.12 | Covered |
| FR24 | 3 | 3.1 | Covered |
| FR24a | 3 | 3.7 | Covered |
| FR24b | 3 | 3.7 | Covered |
| FR24c | 3 | 3.7 | Covered |
| FR24d | 3 | 3.7 | Covered |
| FR25 | 3 | 3.1 | Covered |
| FR26 | 3 | 3.2 | Covered |
| FR27 | 3 | 3.2 | Covered |
| FR27a | 3 | 3.4 | Covered |
| FR28 | 3 | 3.5 | Covered |
| FR28a | 3 | 3.5 | Covered |
| FR28b | 3 | 3.5 | Covered |
| FR29 | 3 | 3.6 | Covered |
| FR29a | 3 | 3.6 | Covered |
| FR30 | 3 | 3.4 | Covered |
| FR30a | 3 | 3.9 | Covered |
| FR30b | 3 | 3.8 | Covered |
| FR30c | 3 | 3.4 | Covered |
| FR30d | 3 | 3.10 | Covered |
| FR30e | 3 | 3.6 | Covered |
| FR30f | 3 | 3.4 | Covered |
| FR31 | 4 | 4.1 | Covered |
| FR32 | 4 | 4.1 | Covered |
| FR33 | 4 | 4.3 | Covered |
| FR34 | 4 | 4.3 | Covered |
| FR35 | 4 | 4.2 | Covered |
| FR35a | 4 | 4.2 | Covered |
| FR35b | 4 | 4.2 | Covered |
| FR36 | 4 | 4.4 | Covered |
| FR37 | 4 | 4.9 | Covered |
| FR38 | 4 | 4.5 | Covered |
| FR39 | 4 | 4.6 | Covered |
| FR40 | 4 | 4.7 | Covered |
| FR40a | 4 | 4.7 | Covered |
| FR40b | 4 | 4.7 | Covered |
| FR41 | 4 | 4.4 | Covered |
| FR42 | 4 | 4.6 | Covered |
| FR42a | 4 | 4.5 | Covered |
| FR42b | 4 | 4.5 | Covered |
| FR42c | 4 | 4.8 | Covered |
| FR42d | 4 | 4.8 | Covered |
| FR42e | 4 | 4.5 | Covered |
| FR43 | 3 | 3.2 | Covered |
| FR44 | 3 | 3.2 | Covered |
| FR45 | 3 | 3.5 | Covered |
| FR46 | 4 | 4.10 | Covered |
| FR47 | 5 | 5.1 | Covered |
| FR48 | 5 | 5.2 | Covered |
| FR49 | 5 | 5.3 | Covered |
| FR50 | 5 | 5.5 | Covered |
| FR51 | 5 | 5.5 | Covered |
| FR52 | 5 | 5.4 | Covered |
| FR53 | 2 | 2.4 | Covered |
| FR54 | 3 | 3.11 | Covered |
| FR55 | 4 | 4.10 | Covered |
| FR56 | 1 | 1.4, 1.5, 1.6 | Covered |
| FR57 | 1 | 1.7 | Covered |
| FR58 | 5 | 5.5 | Covered |
| FR59 | 6 | 6.1 | Covered |
| FR60 | 6 | 6.1 | Covered |
| FR61 | 6 | 6.7 | Covered |
| FR62 | 6 | 6.2 | Covered |
| FR63 | 6 | 6.2 | Covered |
| FR64 | 6 | 6.3 | Covered |
| FR65 | 6 | 6.3 | Covered |
| FR66 | 6 | 6.3 | Covered |
| FR67 | 6 | 6.4 | Covered |
| FR68 | 6 | 6.4 | Covered |
| FR69 | 6 | 6.5 | Covered |
| FR70 | 6 | 6.5 | Covered |
| FR71 | 6 | 6.5 | Covered |
| FR72 | 6 | 6.5 | Covered |
| FR73 | 6 | 6.6, 6.9 | Covered |
| FR74 | 6 | 6.6 | Covered |
| FR75 | 6 | 6.7 | Covered |
| FR76 | 6 | 6.7 | Covered |
| FR77 | 6 | 6.1, 6.2, 6.3, 6.4, 6.6 | Covered |

**Coverage:** 100/100 FRs (100%)

---

## Summary

This epic breakdown transforms the LumiKB PRD into 97 implementable stories across 8 epics (updated 2025-12-08):

| Epic | Stories | Key Deliverables |
|------|---------|------------------|
| **1. Foundation** | 10 | Auth, audit infrastructure, dashboard shell, demo KB |
| **2. KB & Docs** | 12 | KB management, document upload/processing pipeline |
| **3. Search & Citations** | 11 | Semantic search, citation system, cross-KB search |
| **4. Chat & Generation** | 10 | Chat interface, draft generation, export |
| **5. Admin & Polish** | 20 (+9 from retrospective/scope) | Admin dashboard, **Epic 3&4 integration**, **Docker E2E**, **User/Group/Role management UI**, **Document tags/processing/filtering**, **Document Chunk Viewer**, onboarding, UX polish |
| **6. Document Lifecycle** | 9 | Archive, restore, purge, clear failed, duplicate detection, replace documents |

**Epic 6 Added (2025-12-07):**
- Story 6.1: Archive Document Backend (3 pts)
- Story 6.2: Restore Document Backend (3 pts)
- Story 6.3: Purge Document Backend (5 pts)
- Story 6.4: Clear Failed Document Backend (3 pts)
- Story 6.5: Duplicate Detection & Auto-Clear Backend (5 pts)
- Story 6.6: Replace Document Backend (5 pts)
- Story 6.7: Archive Management UI (5 pts)
- Story 6.8: Document List Archive/Clear Actions UI (3 pts)
- Story 6.9: Duplicate Upload & Replace UI (3 pts)
- Total: 35 story points, FR59-FR77 coverage
- Updated total: 72 stories (was 63)

**Epic 5 Scope Changes (2025-12-07):**
- Added Story 5.25: Document Chunk Viewer - Backend API (HIGH) - API endpoints for chunk retrieval and document streaming
- Added Story 5.26: Document Chunk Viewer - Frontend UI (HIGH) - Split-pane viewer with format-specific highlighting
- Updated total: 63 stories (was 61)

**Epic 5 Scope Changes (2025-12-06):**
- Added Story 5.22: Document Tags (MEDIUM) - Tags for documents (like KB tags), stored in metadata JSONB
- Added Story 5.23: Document Processing Progress Screen (HIGH/PRIORITY) - Detailed processing status view with per-step status
- Added Story 5.24: KB Dashboard Document Filtering & Pagination (MEDIUM) - Filter and paginate document list
- Updated total: 61 stories (was 58)

**Epic 5 Scope Changes (2025-12-05):**
- Added Story 5.18: User Management UI (HIGH) - Admin UI for user CRUD
- Added Story 5.19: Group Management (MEDIUM) - User groups for bulk permission management
- Added Story 5.20: Role & KB Permission Management UI (MEDIUM) - UI for KB permission assignment
- Added Story 5.21: Theme System (LOW) - Multiple color themes (Light Blue, Dark Navy) with theme selector
- Updated total: 58 stories (was 54)

**Previous Scope Changes (2025-11-30):**
- Added Story 5.0: Epic 3 & 4 Integration Completion (CRITICAL)
- Added Story 5.16: Docker E2E Testing Infrastructure (HIGH)

**Design Principles Applied:**
- **Citation-first**: Every AI output story includes citation AC
- **User value per epic**: Each epic has demo-able capability
- **Single-session stories**: Each story completable in one dev session
- **100% FR coverage**: All 85 requirements mapped to stories

---

_For implementation: Use the `dev-story` workflow to execute individual stories from this breakdown._

_This document will be updated during implementation to incorporate technical discoveries and refinements._
